{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adadelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30001, 24)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_excel('A:\\credit_cards-master\\credit_cards-master\\default of credit card clients.xls')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29966, 24)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>SEX</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>AGE</td>\n",
       "      <td>PAY_0</td>\n",
       "      <td>PAY_2</td>\n",
       "      <td>PAY_3</td>\n",
       "      <td>PAY_4</td>\n",
       "      <td>PAY_5</td>\n",
       "      <td>...</td>\n",
       "      <td>BILL_AMT3</td>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1   X2         X3        X4   X5     X6     X7     X8     X9  \\\n",
       "ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n",
       "1       20000    2          2         1   24      2      2     -1     -1   \n",
       "2      120000    2          2         2   26     -1      2      0      0   \n",
       "3       90000    2          2         2   34      0      0      0      0   \n",
       "4       50000    2          2         1   37      0      0      0      0   \n",
       "\n",
       "      X10    ...           X14        X15        X16        X17       X18  \\\n",
       "ID  PAY_5    ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1   \n",
       "1      -2    ...           689          0          0          0         0   \n",
       "2       0    ...          2682       3272       3455       3261         0   \n",
       "3       0    ...         13559      14331      14948      15549      1518   \n",
       "4       0    ...         49291      28314      28959      29547      2000   \n",
       "\n",
       "         X19       X20       X21       X22       X23  \n",
       "ID  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "1        689         0         0         0         0  \n",
       "2       1000      1000      1000         0      2000  \n",
       "3       1500      1000      1000      1000      5000  \n",
       "4       2019      1200      1100      1069      1000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data.Y\n",
    "y.drop(axis=1,index=['ID'],inplace=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "X=data.drop(columns='Y')\n",
    "#X=data\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1 X2 X3 X4  X5  X6 X7  X8  X9 X10  ...     X14    X15    X16    X17  \\\n",
       "1   20000  2  2  1  24   2  2  -1  -1  -2  ...     689      0      0      0   \n",
       "2  120000  2  2  2  26  -1  2   0   0   0  ...    2682   3272   3455   3261   \n",
       "3   90000  2  2  2  34   0  0   0   0   0  ...   13559  14331  14948  15549   \n",
       "4   50000  2  2  1  37   0  0   0   0   0  ...   49291  28314  28959  29547   \n",
       "5   50000  1  2  1  57  -1  0  -1   0   0  ...   35835  20940  19146  19131   \n",
       "\n",
       "    X18    X19    X20   X21   X22   X23  \n",
       "1     0    689      0     0     0     0  \n",
       "2     0   1000   1000  1000     0  2000  \n",
       "3  1518   1500   1000  1000  1000  5000  \n",
       "4  2000   2019   1200  1100  1069  1000  \n",
       "5  2000  36681  10000  9000   689   679  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "X.drop(axis=1,index=['ID'],inplace=True)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulm\\Anaconda3\\envs\\pyten\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\paulm\\Anaconda3\\envs\\pyten\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#normalise\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#X=normalize(X, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "#print(X[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-5dfe9ee471fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_plot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_plot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"X2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"X3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"X4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"X5\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mpairplot\u001b[1;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, dropna, plot_kws, diag_kws, grid_kws, size)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                     \u001b[0mhue_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhue_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m                     \u001b[0mdiag_sharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiag_sharey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                     height=height, aspect=aspect, dropna=dropna, **grid_kws)\n\u001b[0m\u001b[0;32m   2085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m     \u001b[1;31m# Add the markers here as PairGrid has figured out how many levels of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, hue, hue_order, palette, hue_kws, vars, x_vars, y_vars, diag_sharey, height, aspect, despine, dropna, size)\u001b[0m\n\u001b[0;32m   1288\u001b[0m                                       index=data.index)\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m             \u001b[0mhue_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m                 \u001b[1;31m# Filter NA from the list of unique hue names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pyten\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Y'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_plot=pd.DataFrame(X)\n",
    "seaborn.pairplot(X_plot,hue='Y',vars=[\"X1\", \"X2\",\"X3\",\"X4\",\"X5\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=data['Y']\n",
    "\n",
    "print(y.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot=pd.DataFrame(X)\n",
    "seaborn.pairplot(X_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#reshapes\n",
    "#X_train=X_train.as_matrix()\n",
    "#X_test=X_test.as_matrix()\n",
    "print(type(X_test))\n",
    "#X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1,1)\n",
    "#X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Dense(32, activation='relu',input_shape=(23,)))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                768       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 15,361\n",
      "Trainable params: 15,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "opt = Adadelta()\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23972 samples, validate on 5993 samples\n",
      "Epoch 1/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1342 - acc: 0.8233 - val_loss: 0.1368 - val_acc: 0.8170\n",
      "Epoch 2/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1340 - acc: 0.8223 - val_loss: 0.1369 - val_acc: 0.8163\n",
      "Epoch 3/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1337 - acc: 0.8232 - val_loss: 0.1381 - val_acc: 0.8146\n",
      "Epoch 4/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1339 - acc: 0.8219 - val_loss: 0.1392 - val_acc: 0.8145\n",
      "Epoch 5/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1334 - acc: 0.8228 - val_loss: 0.1388 - val_acc: 0.8134\n",
      "Epoch 6/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1331 - acc: 0.8230 - val_loss: 0.1381 - val_acc: 0.8134\n",
      "Epoch 7/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1329 - acc: 0.8229 - val_loss: 0.1382 - val_acc: 0.8166\n",
      "Epoch 8/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1329 - acc: 0.8243 - val_loss: 0.1420 - val_acc: 0.8053\n",
      "Epoch 9/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1330 - acc: 0.8237 - val_loss: 0.1390 - val_acc: 0.8166\n",
      "Epoch 10/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1327 - acc: 0.8235 - val_loss: 0.1368 - val_acc: 0.8186\n",
      "Epoch 11/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1320 - acc: 0.8243 - val_loss: 0.1375 - val_acc: 0.8155\n",
      "Epoch 12/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.1323 - acc: 0.8238 - val_loss: 0.1384 - val_acc: 0.8166\n",
      "Epoch 13/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1322 - acc: 0.8243 - val_loss: 0.1394 - val_acc: 0.8123\n",
      "Epoch 14/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1319 - acc: 0.8234 - val_loss: 0.1428 - val_acc: 0.8114\n",
      "Epoch 15/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1319 - acc: 0.8251 - val_loss: 0.1398 - val_acc: 0.8121\n",
      "Epoch 16/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1319 - acc: 0.8251 - val_loss: 0.1394 - val_acc: 0.8166\n",
      "Epoch 17/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1318 - acc: 0.8252 - val_loss: 0.1383 - val_acc: 0.8133\n",
      "Epoch 18/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1312 - acc: 0.8259 - val_loss: 0.1421 - val_acc: 0.8146\n",
      "Epoch 19/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1311 - acc: 0.8264 - val_loss: 0.1395 - val_acc: 0.8133\n",
      "Epoch 20/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1310 - acc: 0.8247 - val_loss: 0.1429 - val_acc: 0.8091\n",
      "Epoch 21/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1309 - acc: 0.8252 - val_loss: 0.1398 - val_acc: 0.8134\n",
      "Epoch 22/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1310 - acc: 0.8265 - val_loss: 0.1393 - val_acc: 0.8160\n",
      "Epoch 23/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1306 - acc: 0.8265 - val_loss: 0.1413 - val_acc: 0.8128\n",
      "Epoch 24/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1305 - acc: 0.8277 - val_loss: 0.1393 - val_acc: 0.8168\n",
      "Epoch 25/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1299 - acc: 0.8289 - val_loss: 0.1431 - val_acc: 0.8106\n",
      "Epoch 26/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1303 - acc: 0.8265 - val_loss: 0.1424 - val_acc: 0.8160\n",
      "Epoch 27/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1303 - acc: 0.8271 - val_loss: 0.1418 - val_acc: 0.8160\n",
      "Epoch 28/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1300 - acc: 0.8273 - val_loss: 0.1409 - val_acc: 0.8148\n",
      "Epoch 29/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1300 - acc: 0.8280 - val_loss: 0.1413 - val_acc: 0.8139\n",
      "Epoch 30/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1295 - acc: 0.8274 - val_loss: 0.1407 - val_acc: 0.8128\n",
      "Epoch 31/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1294 - acc: 0.8291 - val_loss: 0.1432 - val_acc: 0.8088\n",
      "Epoch 32/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.1289 - acc: 0.8289 - val_loss: 0.1433 - val_acc: 0.8111\n",
      "Epoch 33/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1290 - acc: 0.8284 - val_loss: 0.1435 - val_acc: 0.8118\n",
      "Epoch 34/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1288 - acc: 0.8301 - val_loss: 0.1422 - val_acc: 0.8129\n",
      "Epoch 35/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1289 - acc: 0.8307 - val_loss: 0.1438 - val_acc: 0.8153\n",
      "Epoch 36/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1286 - acc: 0.8298 - val_loss: 0.1431 - val_acc: 0.8156\n",
      "Epoch 37/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.1281 - acc: 0.8302 - val_loss: 0.1406 - val_acc: 0.8119\n",
      "Epoch 38/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.1287 - acc: 0.8296 - val_loss: 0.1443 - val_acc: 0.8126\n",
      "Epoch 39/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.1282 - acc: 0.8309 - val_loss: 0.1446 - val_acc: 0.8138\n",
      "Epoch 40/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.1279 - acc: 0.8323 - val_loss: 0.1423 - val_acc: 0.8113\n",
      "Epoch 41/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.1278 - acc: 0.8305 - val_loss: 0.1420 - val_acc: 0.8129\n",
      "Epoch 42/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.1275 - acc: 0.8331 - val_loss: 0.1455 - val_acc: 0.8113\n",
      "Epoch 43/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.1277 - acc: 0.8308 - val_loss: 0.1425 - val_acc: 0.8108\n",
      "Epoch 44/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1271 - acc: 0.8327 - val_loss: 0.1431 - val_acc: 0.8098\n",
      "Epoch 45/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.1271 - acc: 0.8328 - val_loss: 0.1448 - val_acc: 0.8111\n",
      "Epoch 46/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1263 - acc: 0.8329 - val_loss: 0.1474 - val_acc: 0.8126\n",
      "Epoch 47/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.1263 - acc: 0.8328 - val_loss: 0.1467 - val_acc: 0.8101\n",
      "Epoch 48/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1264 - acc: 0.8342 - val_loss: 0.1428 - val_acc: 0.8111\n",
      "Epoch 49/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.1263 - acc: 0.8342 - val_loss: 0.1450 - val_acc: 0.8069\n",
      "Epoch 50/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1257 - acc: 0.8349 - val_loss: 0.1443 - val_acc: 0.8113\n",
      "Epoch 51/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1254 - acc: 0.8359 - val_loss: 0.1435 - val_acc: 0.8148\n",
      "Epoch 52/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1257 - acc: 0.8346 - val_loss: 0.1462 - val_acc: 0.8089\n",
      "Epoch 53/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.1253 - acc: 0.8353 - val_loss: 0.1459 - val_acc: 0.8051\n",
      "Epoch 54/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.1248 - acc: 0.8353 - val_loss: 0.1450 - val_acc: 0.8101\n",
      "Epoch 55/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1249 - acc: 0.8353 - val_loss: 0.1461 - val_acc: 0.8123\n",
      "Epoch 56/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1242 - acc: 0.8373 - val_loss: 0.1457 - val_acc: 0.8113\n",
      "Epoch 57/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.1246 - acc: 0.8369 - val_loss: 0.1439 - val_acc: 0.8109\n",
      "Epoch 58/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1241 - acc: 0.8375 - val_loss: 0.1449 - val_acc: 0.8073\n",
      "Epoch 59/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1239 - acc: 0.8375 - val_loss: 0.1461 - val_acc: 0.8076\n",
      "Epoch 60/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1239 - acc: 0.8377 - val_loss: 0.1489 - val_acc: 0.8081\n",
      "Epoch 61/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1231 - acc: 0.8379 - val_loss: 0.1479 - val_acc: 0.8076\n",
      "Epoch 62/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1230 - acc: 0.8390 - val_loss: 0.1546 - val_acc: 0.8006\n",
      "Epoch 63/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1224 - acc: 0.8402 - val_loss: 0.1469 - val_acc: 0.8094\n",
      "Epoch 64/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1225 - acc: 0.8403 - val_loss: 0.1494 - val_acc: 0.8094\n",
      "Epoch 65/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1225 - acc: 0.8409 - val_loss: 0.1505 - val_acc: 0.8028\n",
      "Epoch 66/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1217 - acc: 0.8404 - val_loss: 0.1471 - val_acc: 0.8101\n",
      "Epoch 67/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1216 - acc: 0.8414 - val_loss: 0.1489 - val_acc: 0.8043\n",
      "Epoch 68/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1213 - acc: 0.8421 - val_loss: 0.1506 - val_acc: 0.8106\n",
      "Epoch 69/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.1211 - acc: 0.8429 - val_loss: 0.1517 - val_acc: 0.8104\n",
      "Epoch 70/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1206 - acc: 0.8421 - val_loss: 0.1513 - val_acc: 0.8038\n",
      "Epoch 71/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1208 - acc: 0.8440 - val_loss: 0.1479 - val_acc: 0.8089\n",
      "Epoch 72/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1201 - acc: 0.8438 - val_loss: 0.1515 - val_acc: 0.7996\n",
      "Epoch 73/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.1197 - acc: 0.8432 - val_loss: 0.1474 - val_acc: 0.8076\n",
      "Epoch 74/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.1197 - acc: 0.8426 - val_loss: 0.1491 - val_acc: 0.8044\n",
      "Epoch 75/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1192 - acc: 0.8437 - val_loss: 0.1495 - val_acc: 0.8079\n",
      "Epoch 76/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1189 - acc: 0.8452 - val_loss: 0.1487 - val_acc: 0.8081\n",
      "Epoch 77/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.1194 - acc: 0.8450 - val_loss: 0.1531 - val_acc: 0.8003\n",
      "Epoch 78/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1186 - acc: 0.8451 - val_loss: 0.1531 - val_acc: 0.8036\n",
      "Epoch 79/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1182 - acc: 0.8451 - val_loss: 0.1528 - val_acc: 0.8008\n",
      "Epoch 80/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.1180 - acc: 0.8473 - val_loss: 0.1519 - val_acc: 0.8064\n",
      "Epoch 81/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1176 - acc: 0.8480 - val_loss: 0.1521 - val_acc: 0.8068\n",
      "Epoch 82/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1175 - acc: 0.8469 - val_loss: 0.1518 - val_acc: 0.8058\n",
      "Epoch 83/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1165 - acc: 0.8477 - val_loss: 0.1538 - val_acc: 0.8028\n",
      "Epoch 84/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1172 - acc: 0.8482 - val_loss: 0.1594 - val_acc: 0.8038\n",
      "Epoch 85/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1166 - acc: 0.8478 - val_loss: 0.1617 - val_acc: 0.8024\n",
      "Epoch 86/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1162 - acc: 0.8476 - val_loss: 0.1534 - val_acc: 0.8026\n",
      "Epoch 87/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.1157 - acc: 0.8495 - val_loss: 0.1529 - val_acc: 0.8046\n",
      "Epoch 88/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.1155 - acc: 0.8494 - val_loss: 0.1559 - val_acc: 0.8026\n",
      "Epoch 89/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.1147 - acc: 0.8512 - val_loss: 0.1557 - val_acc: 0.8016\n",
      "Epoch 90/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.1142 - acc: 0.8513 - val_loss: 0.1537 - val_acc: 0.7993\n",
      "Epoch 91/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.1145 - acc: 0.8507 - val_loss: 0.1552 - val_acc: 0.7974\n",
      "Epoch 92/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.1142 - acc: 0.8511 - val_loss: 0.1534 - val_acc: 0.8036\n",
      "Epoch 93/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.1136 - acc: 0.8522 - val_loss: 0.1569 - val_acc: 0.7999\n",
      "Epoch 94/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1134 - acc: 0.8517 - val_loss: 0.1550 - val_acc: 0.8043\n",
      "Epoch 95/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.1130 - acc: 0.8524 - val_loss: 0.1562 - val_acc: 0.7983\n",
      "Epoch 96/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.1126 - acc: 0.8542 - val_loss: 0.1553 - val_acc: 0.7998\n",
      "Epoch 97/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.1125 - acc: 0.8531 - val_loss: 0.1595 - val_acc: 0.8001\n",
      "Epoch 98/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.1119 - acc: 0.8540 - val_loss: 0.1574 - val_acc: 0.8031\n",
      "Epoch 99/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.1107 - acc: 0.8560 - val_loss: 0.1607 - val_acc: 0.8033\n",
      "Epoch 100/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.1108 - acc: 0.8559 - val_loss: 0.1555 - val_acc: 0.7973\n",
      "Epoch 101/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1104 - acc: 0.8547 - val_loss: 0.1580 - val_acc: 0.8016\n",
      "Epoch 102/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1100 - acc: 0.8574 - val_loss: 0.1571 - val_acc: 0.8019\n",
      "Epoch 103/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.1099 - acc: 0.8578 - val_loss: 0.1552 - val_acc: 0.8009\n",
      "Epoch 104/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.1097 - acc: 0.8595 - val_loss: 0.1587 - val_acc: 0.8018\n",
      "Epoch 105/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1087 - acc: 0.8602 - val_loss: 0.1617 - val_acc: 0.7951\n",
      "Epoch 106/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.1084 - acc: 0.8584 - val_loss: 0.1572 - val_acc: 0.8019\n",
      "Epoch 107/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1086 - acc: 0.8588 - val_loss: 0.1592 - val_acc: 0.7999\n",
      "Epoch 108/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.1078 - acc: 0.8605 - val_loss: 0.1576 - val_acc: 0.8031\n",
      "Epoch 109/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.1082 - acc: 0.8586 - val_loss: 0.1603 - val_acc: 0.7954\n",
      "Epoch 110/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1070 - acc: 0.8604 - val_loss: 0.1568 - val_acc: 0.8009\n",
      "Epoch 111/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.1068 - acc: 0.8612 - val_loss: 0.1614 - val_acc: 0.8006\n",
      "Epoch 112/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.1068 - acc: 0.8608 - val_loss: 0.1623 - val_acc: 0.7963\n",
      "Epoch 113/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1063 - acc: 0.8625 - val_loss: 0.1614 - val_acc: 0.7938\n",
      "Epoch 114/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1058 - acc: 0.8633 - val_loss: 0.1593 - val_acc: 0.8008\n",
      "Epoch 115/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1053 - acc: 0.8636 - val_loss: 0.1644 - val_acc: 0.7998\n",
      "Epoch 116/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.1054 - acc: 0.8634 - val_loss: 0.1619 - val_acc: 0.7981\n",
      "Epoch 117/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.1052 - acc: 0.8615 - val_loss: 0.1615 - val_acc: 0.7983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1041 - acc: 0.8643 - val_loss: 0.1643 - val_acc: 0.7969\n",
      "Epoch 119/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.1037 - acc: 0.8668 - val_loss: 0.1610 - val_acc: 0.7949\n",
      "Epoch 120/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1036 - acc: 0.8655 - val_loss: 0.1659 - val_acc: 0.7964\n",
      "Epoch 121/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.1030 - acc: 0.8675 - val_loss: 0.1841 - val_acc: 0.7717\n",
      "Epoch 122/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1028 - acc: 0.8685 - val_loss: 0.1655 - val_acc: 0.7889\n",
      "Epoch 123/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1023 - acc: 0.8685 - val_loss: 0.1677 - val_acc: 0.7884\n",
      "Epoch 124/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1017 - acc: 0.8693 - val_loss: 0.1635 - val_acc: 0.7958\n",
      "Epoch 125/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.1018 - acc: 0.8678 - val_loss: 0.1751 - val_acc: 0.7812\n",
      "Epoch 126/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1013 - acc: 0.8690 - val_loss: 0.1651 - val_acc: 0.7933\n",
      "Epoch 127/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1010 - acc: 0.8696 - val_loss: 0.1644 - val_acc: 0.7956\n",
      "Epoch 128/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.1000 - acc: 0.8713 - val_loss: 0.1632 - val_acc: 0.7943\n",
      "Epoch 129/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.1001 - acc: 0.8712 - val_loss: 0.1681 - val_acc: 0.7921\n",
      "Epoch 130/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0996 - acc: 0.8707 - val_loss: 0.1668 - val_acc: 0.7893\n",
      "Epoch 131/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0996 - acc: 0.8732 - val_loss: 0.1707 - val_acc: 0.7948\n",
      "Epoch 132/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0992 - acc: 0.8738 - val_loss: 0.1662 - val_acc: 0.7966\n",
      "Epoch 133/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0991 - acc: 0.8729 - val_loss: 0.1675 - val_acc: 0.7909\n",
      "Epoch 134/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0984 - acc: 0.8740 - val_loss: 0.1692 - val_acc: 0.7884\n",
      "Epoch 135/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0982 - acc: 0.8746 - val_loss: 0.1681 - val_acc: 0.7981\n",
      "Epoch 136/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0978 - acc: 0.8746 - val_loss: 0.1719 - val_acc: 0.7859\n",
      "Epoch 137/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0977 - acc: 0.8756 - val_loss: 0.1699 - val_acc: 0.7944\n",
      "Epoch 138/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0973 - acc: 0.8759 - val_loss: 0.1718 - val_acc: 0.7879\n",
      "Epoch 139/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0974 - acc: 0.8745 - val_loss: 0.1803 - val_acc: 0.7797\n",
      "Epoch 140/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0968 - acc: 0.8775 - val_loss: 0.1713 - val_acc: 0.7901\n",
      "Epoch 141/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0963 - acc: 0.8769 - val_loss: 0.1733 - val_acc: 0.7858\n",
      "Epoch 142/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.0961 - acc: 0.8778 - val_loss: 0.1721 - val_acc: 0.7904\n",
      "Epoch 143/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0952 - acc: 0.8787 - val_loss: 0.1715 - val_acc: 0.7903\n",
      "Epoch 144/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0951 - acc: 0.8786 - val_loss: 0.1753 - val_acc: 0.7817\n",
      "Epoch 145/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0945 - acc: 0.8790 - val_loss: 0.1701 - val_acc: 0.7931\n",
      "Epoch 146/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0946 - acc: 0.8794 - val_loss: 0.1808 - val_acc: 0.7672\n",
      "Epoch 147/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0940 - acc: 0.8807 - val_loss: 0.1725 - val_acc: 0.7918\n",
      "Epoch 148/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0943 - acc: 0.8813 - val_loss: 0.1720 - val_acc: 0.7844\n",
      "Epoch 149/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0939 - acc: 0.8800 - val_loss: 0.1707 - val_acc: 0.7901\n",
      "Epoch 150/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0935 - acc: 0.8815 - val_loss: 0.1815 - val_acc: 0.7774\n",
      "Epoch 151/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0924 - acc: 0.8834 - val_loss: 0.1733 - val_acc: 0.7881\n",
      "Epoch 152/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0924 - acc: 0.8821 - val_loss: 0.1802 - val_acc: 0.7746\n",
      "Epoch 153/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0918 - acc: 0.8825 - val_loss: 0.1793 - val_acc: 0.7866\n",
      "Epoch 154/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0912 - acc: 0.8832 - val_loss: 0.1750 - val_acc: 0.7851\n",
      "Epoch 155/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0910 - acc: 0.8857 - val_loss: 0.1817 - val_acc: 0.7814\n",
      "Epoch 156/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0907 - acc: 0.8852 - val_loss: 0.1748 - val_acc: 0.7879\n",
      "Epoch 157/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0907 - acc: 0.8857 - val_loss: 0.1729 - val_acc: 0.7908\n",
      "Epoch 158/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0905 - acc: 0.8860 - val_loss: 0.1848 - val_acc: 0.7814\n",
      "Epoch 159/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0902 - acc: 0.8871 - val_loss: 0.1855 - val_acc: 0.7749\n",
      "Epoch 160/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0896 - acc: 0.8870 - val_loss: 0.1810 - val_acc: 0.7822\n",
      "Epoch 161/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0899 - acc: 0.8868 - val_loss: 0.1830 - val_acc: 0.7878\n",
      "Epoch 162/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0894 - acc: 0.8874 - val_loss: 0.1753 - val_acc: 0.7824\n",
      "Epoch 163/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0887 - acc: 0.8884 - val_loss: 0.1739 - val_acc: 0.7896\n",
      "Epoch 164/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0888 - acc: 0.8889 - val_loss: 0.1747 - val_acc: 0.7911\n",
      "Epoch 165/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0880 - acc: 0.8895 - val_loss: 0.1767 - val_acc: 0.7831\n",
      "Epoch 166/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0882 - acc: 0.8891 - val_loss: 0.1805 - val_acc: 0.7861\n",
      "Epoch 167/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0882 - acc: 0.8897 - val_loss: 0.1738 - val_acc: 0.7871\n",
      "Epoch 168/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0878 - acc: 0.8905 - val_loss: 0.1792 - val_acc: 0.7836\n",
      "Epoch 169/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0866 - acc: 0.8906 - val_loss: 0.1777 - val_acc: 0.7871\n",
      "Epoch 170/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0867 - acc: 0.8922 - val_loss: 0.1816 - val_acc: 0.7811\n",
      "Epoch 171/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0865 - acc: 0.8924 - val_loss: 0.1775 - val_acc: 0.7918\n",
      "Epoch 172/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0864 - acc: 0.8926 - val_loss: 0.1794 - val_acc: 0.7806\n",
      "Epoch 173/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0857 - acc: 0.8920 - val_loss: 0.1774 - val_acc: 0.7863\n",
      "Epoch 174/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0853 - acc: 0.8930 - val_loss: 0.1799 - val_acc: 0.7868\n",
      "Epoch 175/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0848 - acc: 0.8946 - val_loss: 0.1885 - val_acc: 0.7782\n",
      "Epoch 176/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0849 - acc: 0.8945 - val_loss: 0.1833 - val_acc: 0.7787\n",
      "Epoch 177/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0844 - acc: 0.8952 - val_loss: 0.1816 - val_acc: 0.7827\n",
      "Epoch 178/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0840 - acc: 0.8963 - val_loss: 0.1856 - val_acc: 0.7794\n",
      "Epoch 179/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0838 - acc: 0.8962 - val_loss: 0.1900 - val_acc: 0.7794\n",
      "Epoch 180/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0837 - acc: 0.8950 - val_loss: 0.1893 - val_acc: 0.7762\n",
      "Epoch 181/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0833 - acc: 0.8955 - val_loss: 0.1903 - val_acc: 0.7776\n",
      "Epoch 182/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0830 - acc: 0.8976 - val_loss: 0.1973 - val_acc: 0.7786\n",
      "Epoch 183/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0823 - acc: 0.8975 - val_loss: 0.1839 - val_acc: 0.7836\n",
      "Epoch 184/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0818 - acc: 0.8984 - val_loss: 0.1968 - val_acc: 0.7676\n",
      "Epoch 185/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0818 - acc: 0.8990 - val_loss: 0.1859 - val_acc: 0.7746\n",
      "Epoch 186/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0814 - acc: 0.8991 - val_loss: 0.1835 - val_acc: 0.7819\n",
      "Epoch 187/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0808 - acc: 0.9006 - val_loss: 0.1891 - val_acc: 0.7784\n",
      "Epoch 188/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0806 - acc: 0.8996 - val_loss: 0.1847 - val_acc: 0.7759\n",
      "Epoch 189/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0806 - acc: 0.9008 - val_loss: 0.1949 - val_acc: 0.7741\n",
      "Epoch 190/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0797 - acc: 0.9007 - val_loss: 0.1943 - val_acc: 0.7694\n",
      "Epoch 191/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0798 - acc: 0.9028 - val_loss: 0.1942 - val_acc: 0.7677\n",
      "Epoch 192/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0793 - acc: 0.9023 - val_loss: 0.1819 - val_acc: 0.7829\n",
      "Epoch 193/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0789 - acc: 0.9033 - val_loss: 0.1882 - val_acc: 0.7779\n",
      "Epoch 194/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0788 - acc: 0.9020 - val_loss: 0.1964 - val_acc: 0.7712\n",
      "Epoch 195/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0787 - acc: 0.9041 - val_loss: 0.1849 - val_acc: 0.7806\n",
      "Epoch 196/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0782 - acc: 0.9040 - val_loss: 0.2057 - val_acc: 0.7686\n",
      "Epoch 197/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0782 - acc: 0.9046 - val_loss: 0.1902 - val_acc: 0.7742\n",
      "Epoch 198/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0780 - acc: 0.9043 - val_loss: 0.1918 - val_acc: 0.7819\n",
      "Epoch 199/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0774 - acc: 0.9055 - val_loss: 0.1933 - val_acc: 0.7739\n",
      "Epoch 200/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0773 - acc: 0.9062 - val_loss: 0.1979 - val_acc: 0.7647\n",
      "Epoch 201/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0772 - acc: 0.9066 - val_loss: 0.1988 - val_acc: 0.7669\n",
      "Epoch 202/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0767 - acc: 0.9071 - val_loss: 0.1886 - val_acc: 0.7806\n",
      "Epoch 203/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0765 - acc: 0.9067 - val_loss: 0.1903 - val_acc: 0.7747\n",
      "Epoch 204/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0762 - acc: 0.9076 - val_loss: 0.1924 - val_acc: 0.7702\n",
      "Epoch 205/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0757 - acc: 0.9095 - val_loss: 0.1877 - val_acc: 0.7782\n",
      "Epoch 206/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0761 - acc: 0.9089 - val_loss: 0.1887 - val_acc: 0.7779\n",
      "Epoch 207/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0756 - acc: 0.9083 - val_loss: 0.1889 - val_acc: 0.7804\n",
      "Epoch 208/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0752 - acc: 0.9080 - val_loss: 0.1901 - val_acc: 0.7729\n",
      "Epoch 209/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0745 - acc: 0.9099 - val_loss: 0.1835 - val_acc: 0.7852\n",
      "Epoch 210/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0743 - acc: 0.9097 - val_loss: 0.1921 - val_acc: 0.7776\n",
      "Epoch 211/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0745 - acc: 0.9100 - val_loss: 0.1919 - val_acc: 0.7734\n",
      "Epoch 212/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0739 - acc: 0.9102 - val_loss: 0.1949 - val_acc: 0.7761\n",
      "Epoch 213/800\n",
      "23972/23972 [==============================] - 2s 71us/step - loss: 0.0738 - acc: 0.9112 - val_loss: 0.1925 - val_acc: 0.7732\n",
      "Epoch 214/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0739 - acc: 0.9125 - val_loss: 0.1965 - val_acc: 0.7706\n",
      "Epoch 215/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0731 - acc: 0.9118 - val_loss: 0.1921 - val_acc: 0.7752\n",
      "Epoch 216/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0732 - acc: 0.9133 - val_loss: 0.2000 - val_acc: 0.7717\n",
      "Epoch 217/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0729 - acc: 0.9131 - val_loss: 0.1940 - val_acc: 0.7761\n",
      "Epoch 218/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0725 - acc: 0.9143 - val_loss: 0.2063 - val_acc: 0.7632\n",
      "Epoch 219/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0724 - acc: 0.9134 - val_loss: 0.1959 - val_acc: 0.7699\n",
      "Epoch 220/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0726 - acc: 0.9133 - val_loss: 0.1984 - val_acc: 0.7702\n",
      "Epoch 221/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0727 - acc: 0.9135 - val_loss: 0.1931 - val_acc: 0.7729\n",
      "Epoch 222/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0722 - acc: 0.9141 - val_loss: 0.2005 - val_acc: 0.7619\n",
      "Epoch 223/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0714 - acc: 0.9144 - val_loss: 0.1983 - val_acc: 0.7736\n",
      "Epoch 224/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0712 - acc: 0.9153 - val_loss: 0.1974 - val_acc: 0.7704\n",
      "Epoch 225/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0706 - acc: 0.9167 - val_loss: 0.2031 - val_acc: 0.7667\n",
      "Epoch 226/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0713 - acc: 0.9153 - val_loss: 0.2030 - val_acc: 0.7672\n",
      "Epoch 227/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0704 - acc: 0.9172 - val_loss: 0.1936 - val_acc: 0.7774\n",
      "Epoch 228/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0706 - acc: 0.9162 - val_loss: 0.2029 - val_acc: 0.7676\n",
      "Epoch 229/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0702 - acc: 0.9159 - val_loss: 0.1951 - val_acc: 0.7781\n",
      "Epoch 230/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0698 - acc: 0.9169 - val_loss: 0.1967 - val_acc: 0.7721\n",
      "Epoch 231/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0693 - acc: 0.9181 - val_loss: 0.2039 - val_acc: 0.7581\n",
      "Epoch 232/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0693 - acc: 0.9176 - val_loss: 0.1950 - val_acc: 0.7736\n",
      "Epoch 233/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0693 - acc: 0.9177 - val_loss: 0.2049 - val_acc: 0.7617\n",
      "Epoch 234/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0692 - acc: 0.9182 - val_loss: 0.2025 - val_acc: 0.7661\n",
      "Epoch 235/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0692 - acc: 0.9181 - val_loss: 0.2053 - val_acc: 0.7631\n",
      "Epoch 236/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0687 - acc: 0.9189 - val_loss: 0.1921 - val_acc: 0.7781\n",
      "Epoch 237/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0681 - acc: 0.9195 - val_loss: 0.2017 - val_acc: 0.7719\n",
      "Epoch 238/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0681 - acc: 0.9196 - val_loss: 0.2012 - val_acc: 0.7679\n",
      "Epoch 239/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0681 - acc: 0.9190 - val_loss: 0.1950 - val_acc: 0.7746\n",
      "Epoch 240/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0680 - acc: 0.9184 - val_loss: 0.2043 - val_acc: 0.7676\n",
      "Epoch 241/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0675 - acc: 0.9212 - val_loss: 0.2008 - val_acc: 0.7704\n",
      "Epoch 242/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0676 - acc: 0.9188 - val_loss: 0.1985 - val_acc: 0.7746\n",
      "Epoch 243/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0672 - acc: 0.9210 - val_loss: 0.2082 - val_acc: 0.7581\n",
      "Epoch 244/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0671 - acc: 0.9204 - val_loss: 0.1980 - val_acc: 0.7699\n",
      "Epoch 245/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0669 - acc: 0.9205 - val_loss: 0.2078 - val_acc: 0.7629\n",
      "Epoch 246/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0668 - acc: 0.9198 - val_loss: 0.2165 - val_acc: 0.7490\n",
      "Epoch 247/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0659 - acc: 0.9235 - val_loss: 0.1999 - val_acc: 0.7742\n",
      "Epoch 248/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0663 - acc: 0.9221 - val_loss: 0.2009 - val_acc: 0.7702\n",
      "Epoch 249/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0659 - acc: 0.9222 - val_loss: 0.2062 - val_acc: 0.7674\n",
      "Epoch 250/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0651 - acc: 0.9222 - val_loss: 0.1971 - val_acc: 0.7776\n",
      "Epoch 251/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0656 - acc: 0.9238 - val_loss: 0.2062 - val_acc: 0.7664\n",
      "Epoch 252/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0659 - acc: 0.9229 - val_loss: 0.2085 - val_acc: 0.7641\n",
      "Epoch 253/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0655 - acc: 0.9233 - val_loss: 0.2152 - val_acc: 0.7676\n",
      "Epoch 254/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0651 - acc: 0.9233 - val_loss: 0.2026 - val_acc: 0.7699\n",
      "Epoch 255/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0651 - acc: 0.9229 - val_loss: 0.1968 - val_acc: 0.7727\n",
      "Epoch 256/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0646 - acc: 0.9251 - val_loss: 0.2005 - val_acc: 0.7724\n",
      "Epoch 257/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0642 - acc: 0.9259 - val_loss: 0.2226 - val_acc: 0.7601\n",
      "Epoch 258/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0645 - acc: 0.9241 - val_loss: 0.2050 - val_acc: 0.7697\n",
      "Epoch 259/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0643 - acc: 0.9240 - val_loss: 0.2015 - val_acc: 0.7731\n",
      "Epoch 260/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0639 - acc: 0.9252 - val_loss: 0.2019 - val_acc: 0.7696\n",
      "Epoch 261/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0643 - acc: 0.9252 - val_loss: 0.2078 - val_acc: 0.7664\n",
      "Epoch 262/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0640 - acc: 0.9255 - val_loss: 0.2050 - val_acc: 0.7671\n",
      "Epoch 263/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0632 - acc: 0.9273 - val_loss: 0.2012 - val_acc: 0.7717\n",
      "Epoch 264/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0636 - acc: 0.9255 - val_loss: 0.2076 - val_acc: 0.7652\n",
      "Epoch 265/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0630 - acc: 0.9269 - val_loss: 0.2133 - val_acc: 0.7651\n",
      "Epoch 266/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0628 - acc: 0.9272 - val_loss: 0.2058 - val_acc: 0.7624\n",
      "Epoch 267/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0628 - acc: 0.9275 - val_loss: 0.2065 - val_acc: 0.7657\n",
      "Epoch 268/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0630 - acc: 0.9267 - val_loss: 0.2034 - val_acc: 0.7691\n",
      "Epoch 269/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0626 - acc: 0.9272 - val_loss: 0.2104 - val_acc: 0.7659\n",
      "Epoch 270/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0625 - acc: 0.9278 - val_loss: 0.2180 - val_acc: 0.7611\n",
      "Epoch 271/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0625 - acc: 0.9267 - val_loss: 0.2089 - val_acc: 0.7651\n",
      "Epoch 272/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0622 - acc: 0.9279 - val_loss: 0.1972 - val_acc: 0.7777\n",
      "Epoch 273/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0617 - acc: 0.9285 - val_loss: 0.2104 - val_acc: 0.7656\n",
      "Epoch 274/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0621 - acc: 0.9267 - val_loss: 0.2180 - val_acc: 0.7631\n",
      "Epoch 275/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0615 - acc: 0.9297 - val_loss: 0.2105 - val_acc: 0.7679\n",
      "Epoch 276/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0615 - acc: 0.9284 - val_loss: 0.2088 - val_acc: 0.7652\n",
      "Epoch 277/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0614 - acc: 0.9284 - val_loss: 0.2170 - val_acc: 0.7651\n",
      "Epoch 278/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0609 - acc: 0.9304 - val_loss: 0.2183 - val_acc: 0.7601\n",
      "Epoch 279/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0605 - acc: 0.9307 - val_loss: 0.2123 - val_acc: 0.7674\n",
      "Epoch 280/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0608 - acc: 0.9302 - val_loss: 0.2114 - val_acc: 0.7622\n",
      "Epoch 281/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0606 - acc: 0.9285 - val_loss: 0.2158 - val_acc: 0.7626\n",
      "Epoch 282/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0605 - acc: 0.9295 - val_loss: 0.2061 - val_acc: 0.7752\n",
      "Epoch 283/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0604 - acc: 0.9298 - val_loss: 0.2157 - val_acc: 0.7672\n",
      "Epoch 284/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0603 - acc: 0.9309 - val_loss: 0.2083 - val_acc: 0.7709\n",
      "Epoch 285/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0594 - acc: 0.9325 - val_loss: 0.2081 - val_acc: 0.7716\n",
      "Epoch 286/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0597 - acc: 0.9314 - val_loss: 0.2212 - val_acc: 0.7589\n",
      "Epoch 287/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0601 - acc: 0.9313 - val_loss: 0.2115 - val_acc: 0.7687\n",
      "Epoch 288/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0597 - acc: 0.9313 - val_loss: 0.2188 - val_acc: 0.7627\n",
      "Epoch 289/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0590 - acc: 0.9317 - val_loss: 0.2180 - val_acc: 0.7674\n",
      "Epoch 290/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0592 - acc: 0.9314 - val_loss: 0.2044 - val_acc: 0.7739\n",
      "Epoch 291/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0591 - acc: 0.9328 - val_loss: 0.2187 - val_acc: 0.7662\n",
      "Epoch 292/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0593 - acc: 0.9323 - val_loss: 0.2068 - val_acc: 0.7711\n",
      "Epoch 293/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0587 - acc: 0.9324 - val_loss: 0.2111 - val_acc: 0.7664\n",
      "Epoch 294/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0593 - acc: 0.9324 - val_loss: 0.2104 - val_acc: 0.7726\n",
      "Epoch 295/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0589 - acc: 0.9327 - val_loss: 0.2116 - val_acc: 0.7679\n",
      "Epoch 296/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0592 - acc: 0.9327 - val_loss: 0.2067 - val_acc: 0.7694\n",
      "Epoch 297/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0587 - acc: 0.9327 - val_loss: 0.2067 - val_acc: 0.7741\n",
      "Epoch 298/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0582 - acc: 0.9339 - val_loss: 0.2154 - val_acc: 0.7657\n",
      "Epoch 299/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0581 - acc: 0.9340 - val_loss: 0.2265 - val_acc: 0.7537\n",
      "Epoch 300/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0580 - acc: 0.9341 - val_loss: 0.2109 - val_acc: 0.7699\n",
      "Epoch 301/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0578 - acc: 0.9333 - val_loss: 0.2108 - val_acc: 0.7689\n",
      "Epoch 302/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0579 - acc: 0.9347 - val_loss: 0.2181 - val_acc: 0.7642\n",
      "Epoch 303/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0576 - acc: 0.9339 - val_loss: 0.2107 - val_acc: 0.7696\n",
      "Epoch 304/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0574 - acc: 0.9348 - val_loss: 0.2111 - val_acc: 0.7691\n",
      "Epoch 305/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0576 - acc: 0.9338 - val_loss: 0.2089 - val_acc: 0.7729\n",
      "Epoch 306/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0571 - acc: 0.9351 - val_loss: 0.2197 - val_acc: 0.7651\n",
      "Epoch 307/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0576 - acc: 0.9344 - val_loss: 0.2109 - val_acc: 0.7709\n",
      "Epoch 308/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0571 - acc: 0.9353 - val_loss: 0.2178 - val_acc: 0.7654\n",
      "Epoch 309/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0567 - acc: 0.9356 - val_loss: 0.2176 - val_acc: 0.7666\n",
      "Epoch 310/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0566 - acc: 0.9357 - val_loss: 0.2203 - val_acc: 0.7622\n",
      "Epoch 311/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0566 - acc: 0.9351 - val_loss: 0.2168 - val_acc: 0.7662\n",
      "Epoch 312/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0566 - acc: 0.9356 - val_loss: 0.2094 - val_acc: 0.7696\n",
      "Epoch 313/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0565 - acc: 0.9355 - val_loss: 0.2147 - val_acc: 0.7697\n",
      "Epoch 314/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0564 - acc: 0.9345 - val_loss: 0.2134 - val_acc: 0.7657\n",
      "Epoch 315/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0558 - acc: 0.9361 - val_loss: 0.2180 - val_acc: 0.7589\n",
      "Epoch 316/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0562 - acc: 0.9362 - val_loss: 0.2170 - val_acc: 0.7694\n",
      "Epoch 317/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0555 - acc: 0.9369 - val_loss: 0.2194 - val_acc: 0.7604\n",
      "Epoch 318/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0559 - acc: 0.9370 - val_loss: 0.2032 - val_acc: 0.7744\n",
      "Epoch 319/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0556 - acc: 0.9366 - val_loss: 0.2209 - val_acc: 0.7646\n",
      "Epoch 320/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0556 - acc: 0.9363 - val_loss: 0.2084 - val_acc: 0.7697\n",
      "Epoch 321/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0554 - acc: 0.9376 - val_loss: 0.2174 - val_acc: 0.7584\n",
      "Epoch 322/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0555 - acc: 0.9369 - val_loss: 0.2092 - val_acc: 0.7711\n",
      "Epoch 323/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0553 - acc: 0.9370 - val_loss: 0.2093 - val_acc: 0.7707\n",
      "Epoch 324/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0550 - acc: 0.9377 - val_loss: 0.2165 - val_acc: 0.7674\n",
      "Epoch 325/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0547 - acc: 0.9385 - val_loss: 0.2234 - val_acc: 0.7597\n",
      "Epoch 326/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0546 - acc: 0.9385 - val_loss: 0.2194 - val_acc: 0.7634\n",
      "Epoch 327/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0549 - acc: 0.9373 - val_loss: 0.2148 - val_acc: 0.7662\n",
      "Epoch 328/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0550 - acc: 0.9377 - val_loss: 0.2118 - val_acc: 0.7699\n",
      "Epoch 329/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0546 - acc: 0.9392 - val_loss: 0.2233 - val_acc: 0.7627\n",
      "Epoch 330/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0543 - acc: 0.9387 - val_loss: 0.2189 - val_acc: 0.7596\n",
      "Epoch 331/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0549 - acc: 0.9381 - val_loss: 0.2072 - val_acc: 0.7684\n",
      "Epoch 332/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0546 - acc: 0.9381 - val_loss: 0.2208 - val_acc: 0.7584\n",
      "Epoch 333/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0540 - acc: 0.9391 - val_loss: 0.2225 - val_acc: 0.7559\n",
      "Epoch 334/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0539 - acc: 0.9393 - val_loss: 0.2144 - val_acc: 0.7664\n",
      "Epoch 335/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0537 - acc: 0.9391 - val_loss: 0.2224 - val_acc: 0.7594\n",
      "Epoch 336/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0541 - acc: 0.9382 - val_loss: 0.2121 - val_acc: 0.7659\n",
      "Epoch 337/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0540 - acc: 0.9394 - val_loss: 0.2231 - val_acc: 0.7622\n",
      "Epoch 338/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0536 - acc: 0.9395 - val_loss: 0.2171 - val_acc: 0.7612\n",
      "Epoch 339/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0538 - acc: 0.9396 - val_loss: 0.2191 - val_acc: 0.7609\n",
      "Epoch 340/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0531 - acc: 0.9404 - val_loss: 0.2180 - val_acc: 0.7624\n",
      "Epoch 341/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0535 - acc: 0.9408 - val_loss: 0.2173 - val_acc: 0.7652\n",
      "Epoch 342/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0531 - acc: 0.9401 - val_loss: 0.2253 - val_acc: 0.7562\n",
      "Epoch 343/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0533 - acc: 0.9397 - val_loss: 0.2201 - val_acc: 0.7672\n",
      "Epoch 344/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0529 - acc: 0.9417 - val_loss: 0.2217 - val_acc: 0.7656\n",
      "Epoch 345/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0533 - acc: 0.9395 - val_loss: 0.2248 - val_acc: 0.7627\n",
      "Epoch 346/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0527 - acc: 0.9411 - val_loss: 0.2273 - val_acc: 0.7525\n",
      "Epoch 347/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0529 - acc: 0.9408 - val_loss: 0.2200 - val_acc: 0.7570\n",
      "Epoch 348/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0526 - acc: 0.9409 - val_loss: 0.2192 - val_acc: 0.7636\n",
      "Epoch 349/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0522 - acc: 0.9422 - val_loss: 0.2124 - val_acc: 0.7616\n",
      "Epoch 350/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0523 - acc: 0.9413 - val_loss: 0.2132 - val_acc: 0.7661\n",
      "Epoch 351/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0525 - acc: 0.9410 - val_loss: 0.2171 - val_acc: 0.7626\n",
      "Epoch 352/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0524 - acc: 0.9413 - val_loss: 0.2115 - val_acc: 0.7642\n",
      "Epoch 353/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0521 - acc: 0.9422 - val_loss: 0.2145 - val_acc: 0.7662\n",
      "Epoch 354/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0519 - acc: 0.9413 - val_loss: 0.2136 - val_acc: 0.7659\n",
      "Epoch 355/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0523 - acc: 0.9411 - val_loss: 0.2230 - val_acc: 0.7622\n",
      "Epoch 356/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0521 - acc: 0.9421 - val_loss: 0.2218 - val_acc: 0.7621\n",
      "Epoch 357/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0517 - acc: 0.9427 - val_loss: 0.2173 - val_acc: 0.7637\n",
      "Epoch 358/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0520 - acc: 0.9411 - val_loss: 0.2233 - val_acc: 0.7617\n",
      "Epoch 359/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0514 - acc: 0.9426 - val_loss: 0.2239 - val_acc: 0.7581\n",
      "Epoch 360/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0512 - acc: 0.9430 - val_loss: 0.2238 - val_acc: 0.7581\n",
      "Epoch 361/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0513 - acc: 0.9439 - val_loss: 0.2274 - val_acc: 0.7606\n",
      "Epoch 362/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0511 - acc: 0.9433 - val_loss: 0.2155 - val_acc: 0.7671\n",
      "Epoch 363/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0511 - acc: 0.9438 - val_loss: 0.2305 - val_acc: 0.7454\n",
      "Epoch 364/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0513 - acc: 0.9426 - val_loss: 0.2256 - val_acc: 0.7586\n",
      "Epoch 365/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0506 - acc: 0.9438 - val_loss: 0.2255 - val_acc: 0.7626\n",
      "Epoch 366/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0510 - acc: 0.9434 - val_loss: 0.2135 - val_acc: 0.7639\n",
      "Epoch 367/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0508 - acc: 0.9424 - val_loss: 0.2351 - val_acc: 0.7567\n",
      "Epoch 368/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0511 - acc: 0.9431 - val_loss: 0.2194 - val_acc: 0.7642\n",
      "Epoch 369/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0505 - acc: 0.9443 - val_loss: 0.2215 - val_acc: 0.7592\n",
      "Epoch 370/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0513 - acc: 0.9434 - val_loss: 0.2205 - val_acc: 0.7592\n",
      "Epoch 371/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0504 - acc: 0.9445 - val_loss: 0.2194 - val_acc: 0.7597\n",
      "Epoch 372/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0503 - acc: 0.9438 - val_loss: 0.2217 - val_acc: 0.7547\n",
      "Epoch 373/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0504 - acc: 0.9448 - val_loss: 0.2199 - val_acc: 0.7634\n",
      "Epoch 374/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0503 - acc: 0.9436 - val_loss: 0.2150 - val_acc: 0.7607\n",
      "Epoch 375/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0500 - acc: 0.9459 - val_loss: 0.2257 - val_acc: 0.7631\n",
      "Epoch 376/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0498 - acc: 0.9453 - val_loss: 0.2248 - val_acc: 0.7589\n",
      "Epoch 377/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0498 - acc: 0.9454 - val_loss: 0.2191 - val_acc: 0.7631\n",
      "Epoch 378/800\n",
      "23972/23972 [==============================] - 2s 69us/step - loss: 0.0499 - acc: 0.9454 - val_loss: 0.2188 - val_acc: 0.7619\n",
      "Epoch 379/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0505 - acc: 0.9446 - val_loss: 0.2207 - val_acc: 0.7629\n",
      "Epoch 380/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0498 - acc: 0.9454 - val_loss: 0.2196 - val_acc: 0.7634\n",
      "Epoch 381/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0497 - acc: 0.9456 - val_loss: 0.2179 - val_acc: 0.7631\n",
      "Epoch 382/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0496 - acc: 0.9448 - val_loss: 0.2139 - val_acc: 0.7641\n",
      "Epoch 383/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0498 - acc: 0.9450 - val_loss: 0.2149 - val_acc: 0.7641\n",
      "Epoch 384/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0495 - acc: 0.9450 - val_loss: 0.2243 - val_acc: 0.7596\n",
      "Epoch 385/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0493 - acc: 0.9448 - val_loss: 0.2219 - val_acc: 0.7617\n",
      "Epoch 386/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0489 - acc: 0.9463 - val_loss: 0.2188 - val_acc: 0.7627\n",
      "Epoch 387/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0489 - acc: 0.9461 - val_loss: 0.2261 - val_acc: 0.7616\n",
      "Epoch 388/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0491 - acc: 0.9456 - val_loss: 0.2272 - val_acc: 0.7497\n",
      "Epoch 389/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0487 - acc: 0.9458 - val_loss: 0.2160 - val_acc: 0.7576\n",
      "Epoch 390/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0490 - acc: 0.9462 - val_loss: 0.2186 - val_acc: 0.7612\n",
      "Epoch 391/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0490 - acc: 0.9474 - val_loss: 0.2141 - val_acc: 0.7649\n",
      "Epoch 392/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0487 - acc: 0.9464 - val_loss: 0.2239 - val_acc: 0.7517\n",
      "Epoch 393/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0485 - acc: 0.9473 - val_loss: 0.2134 - val_acc: 0.7687\n",
      "Epoch 394/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0489 - acc: 0.9468 - val_loss: 0.2234 - val_acc: 0.7621\n",
      "Epoch 395/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0486 - acc: 0.9460 - val_loss: 0.2177 - val_acc: 0.7619\n",
      "Epoch 396/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0485 - acc: 0.9466 - val_loss: 0.2161 - val_acc: 0.7612\n",
      "Epoch 397/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0486 - acc: 0.9474 - val_loss: 0.2161 - val_acc: 0.7629\n",
      "Epoch 398/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0487 - acc: 0.9464 - val_loss: 0.2241 - val_acc: 0.7609\n",
      "Epoch 399/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0481 - acc: 0.9476 - val_loss: 0.2203 - val_acc: 0.7606\n",
      "Epoch 400/800\n",
      "23972/23972 [==============================] - 2s 72us/step - loss: 0.0481 - acc: 0.9461 - val_loss: 0.2165 - val_acc: 0.7649\n",
      "Epoch 401/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0484 - acc: 0.9474 - val_loss: 0.2304 - val_acc: 0.7529\n",
      "Epoch 402/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0480 - acc: 0.9470 - val_loss: 0.2174 - val_acc: 0.7582\n",
      "Epoch 403/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0477 - acc: 0.9480 - val_loss: 0.2410 - val_acc: 0.7365\n",
      "Epoch 404/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0479 - acc: 0.9474 - val_loss: 0.2276 - val_acc: 0.7570\n",
      "Epoch 405/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0481 - acc: 0.9465 - val_loss: 0.2266 - val_acc: 0.7550\n",
      "Epoch 406/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0476 - acc: 0.9471 - val_loss: 0.2342 - val_acc: 0.7519\n",
      "Epoch 407/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0481 - acc: 0.9470 - val_loss: 0.2167 - val_acc: 0.7584\n",
      "Epoch 408/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0473 - acc: 0.9489 - val_loss: 0.2218 - val_acc: 0.7596\n",
      "Epoch 409/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0471 - acc: 0.9477 - val_loss: 0.2176 - val_acc: 0.7587\n",
      "Epoch 410/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0479 - acc: 0.9471 - val_loss: 0.2352 - val_acc: 0.7480\n",
      "Epoch 411/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0469 - acc: 0.9490 - val_loss: 0.2264 - val_acc: 0.7525\n",
      "Epoch 412/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0477 - acc: 0.9484 - val_loss: 0.2322 - val_acc: 0.7505\n",
      "Epoch 413/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0472 - acc: 0.9484 - val_loss: 0.2246 - val_acc: 0.7574\n",
      "Epoch 414/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0465 - acc: 0.9491 - val_loss: 0.2125 - val_acc: 0.7642\n",
      "Epoch 415/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0474 - acc: 0.9484 - val_loss: 0.2174 - val_acc: 0.7607\n",
      "Epoch 416/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0472 - acc: 0.9483 - val_loss: 0.2197 - val_acc: 0.7564\n",
      "Epoch 417/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0467 - acc: 0.9497 - val_loss: 0.2198 - val_acc: 0.7626\n",
      "Epoch 418/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0468 - acc: 0.9499 - val_loss: 0.2290 - val_acc: 0.7515\n",
      "Epoch 419/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0466 - acc: 0.9482 - val_loss: 0.2184 - val_acc: 0.7572\n",
      "Epoch 420/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0469 - acc: 0.9484 - val_loss: 0.2208 - val_acc: 0.7624\n",
      "Epoch 421/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0468 - acc: 0.9491 - val_loss: 0.2238 - val_acc: 0.7545\n",
      "Epoch 422/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0470 - acc: 0.9496 - val_loss: 0.2297 - val_acc: 0.7522\n",
      "Epoch 423/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0462 - acc: 0.9494 - val_loss: 0.2242 - val_acc: 0.7599\n",
      "Epoch 424/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0465 - acc: 0.9494 - val_loss: 0.2229 - val_acc: 0.7597\n",
      "Epoch 425/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0465 - acc: 0.9500 - val_loss: 0.2263 - val_acc: 0.7564\n",
      "Epoch 426/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0467 - acc: 0.9502 - val_loss: 0.2155 - val_acc: 0.7639\n",
      "Epoch 427/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0468 - acc: 0.9484 - val_loss: 0.2301 - val_acc: 0.7524\n",
      "Epoch 428/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0462 - acc: 0.9505 - val_loss: 0.2254 - val_acc: 0.7574\n",
      "Epoch 429/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0464 - acc: 0.9506 - val_loss: 0.2224 - val_acc: 0.7622\n",
      "Epoch 430/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0462 - acc: 0.9501 - val_loss: 0.2275 - val_acc: 0.7537\n",
      "Epoch 431/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0461 - acc: 0.9497 - val_loss: 0.2266 - val_acc: 0.7557\n",
      "Epoch 432/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.0459 - acc: 0.9502 - val_loss: 0.2197 - val_acc: 0.7624\n",
      "Epoch 433/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0458 - acc: 0.9506 - val_loss: 0.2207 - val_acc: 0.7601\n",
      "Epoch 434/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0459 - acc: 0.9500 - val_loss: 0.2326 - val_acc: 0.7525\n",
      "Epoch 435/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0455 - acc: 0.9508 - val_loss: 0.2302 - val_acc: 0.7559\n",
      "Epoch 436/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0451 - acc: 0.9509 - val_loss: 0.2318 - val_acc: 0.7499\n",
      "Epoch 437/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0454 - acc: 0.9519 - val_loss: 0.2415 - val_acc: 0.7464\n",
      "Epoch 438/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0454 - acc: 0.9513 - val_loss: 0.2366 - val_acc: 0.7477\n",
      "Epoch 439/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0455 - acc: 0.9503 - val_loss: 0.2366 - val_acc: 0.7510\n",
      "Epoch 440/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0457 - acc: 0.9509 - val_loss: 0.2183 - val_acc: 0.7661\n",
      "Epoch 441/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0450 - acc: 0.9503 - val_loss: 0.2188 - val_acc: 0.7591\n",
      "Epoch 442/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0455 - acc: 0.9507 - val_loss: 0.2206 - val_acc: 0.7612\n",
      "Epoch 443/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0453 - acc: 0.9507 - val_loss: 0.2291 - val_acc: 0.7611\n",
      "Epoch 444/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0454 - acc: 0.9505 - val_loss: 0.2267 - val_acc: 0.7602\n",
      "Epoch 445/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0451 - acc: 0.9518 - val_loss: 0.2234 - val_acc: 0.7624\n",
      "Epoch 446/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0448 - acc: 0.9527 - val_loss: 0.2260 - val_acc: 0.7552\n",
      "Epoch 447/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0446 - acc: 0.9519 - val_loss: 0.2195 - val_acc: 0.7611\n",
      "Epoch 448/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0448 - acc: 0.9512 - val_loss: 0.2219 - val_acc: 0.7576\n",
      "Epoch 449/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0449 - acc: 0.9520 - val_loss: 0.2283 - val_acc: 0.7557\n",
      "Epoch 450/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0448 - acc: 0.9521 - val_loss: 0.2374 - val_acc: 0.7470\n",
      "Epoch 451/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0448 - acc: 0.9520 - val_loss: 0.2195 - val_acc: 0.7649\n",
      "Epoch 452/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0449 - acc: 0.9519 - val_loss: 0.2169 - val_acc: 0.7629\n",
      "Epoch 453/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0441 - acc: 0.9525 - val_loss: 0.2194 - val_acc: 0.7631\n",
      "Epoch 454/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0445 - acc: 0.9513 - val_loss: 0.2372 - val_acc: 0.7509\n",
      "Epoch 455/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0443 - acc: 0.9515 - val_loss: 0.2253 - val_acc: 0.7592\n",
      "Epoch 456/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0440 - acc: 0.9535 - val_loss: 0.2313 - val_acc: 0.7509\n",
      "Epoch 457/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0446 - acc: 0.9523 - val_loss: 0.2231 - val_acc: 0.7651\n",
      "Epoch 458/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0441 - acc: 0.9523 - val_loss: 0.2319 - val_acc: 0.7540\n",
      "Epoch 459/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0445 - acc: 0.9513 - val_loss: 0.2155 - val_acc: 0.7612\n",
      "Epoch 460/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0433 - acc: 0.9533 - val_loss: 0.2306 - val_acc: 0.7542\n",
      "Epoch 461/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0441 - acc: 0.9533 - val_loss: 0.2166 - val_acc: 0.7652\n",
      "Epoch 462/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0444 - acc: 0.9525 - val_loss: 0.2340 - val_acc: 0.7512\n",
      "Epoch 463/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0438 - acc: 0.9529 - val_loss: 0.2252 - val_acc: 0.7542\n",
      "Epoch 464/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0439 - acc: 0.9529 - val_loss: 0.2290 - val_acc: 0.7547\n",
      "Epoch 465/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0437 - acc: 0.9535 - val_loss: 0.2321 - val_acc: 0.7505\n",
      "Epoch 466/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0436 - acc: 0.9531 - val_loss: 0.2292 - val_acc: 0.7534\n",
      "Epoch 467/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0436 - acc: 0.9525 - val_loss: 0.2390 - val_acc: 0.7507\n",
      "Epoch 468/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0437 - acc: 0.9533 - val_loss: 0.2241 - val_acc: 0.7624\n",
      "Epoch 469/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0434 - acc: 0.9539 - val_loss: 0.2272 - val_acc: 0.7632\n",
      "Epoch 470/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0433 - acc: 0.9534 - val_loss: 0.2236 - val_acc: 0.7629\n",
      "Epoch 471/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0432 - acc: 0.9542 - val_loss: 0.2276 - val_acc: 0.7579\n",
      "Epoch 472/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0434 - acc: 0.9530 - val_loss: 0.2342 - val_acc: 0.7520\n",
      "Epoch 473/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0433 - acc: 0.9540 - val_loss: 0.2293 - val_acc: 0.7591\n",
      "Epoch 474/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0433 - acc: 0.9539 - val_loss: 0.2403 - val_acc: 0.7495\n",
      "Epoch 475/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0429 - acc: 0.9538 - val_loss: 0.2216 - val_acc: 0.7592\n",
      "Epoch 476/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0431 - acc: 0.9527 - val_loss: 0.2356 - val_acc: 0.7509\n",
      "Epoch 477/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0432 - acc: 0.9537 - val_loss: 0.2392 - val_acc: 0.7474\n",
      "Epoch 478/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0428 - acc: 0.9537 - val_loss: 0.2414 - val_acc: 0.7504\n",
      "Epoch 479/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0427 - acc: 0.9553 - val_loss: 0.2451 - val_acc: 0.7432\n",
      "Epoch 480/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0430 - acc: 0.9534 - val_loss: 0.2270 - val_acc: 0.7639\n",
      "Epoch 481/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0427 - acc: 0.9541 - val_loss: 0.2453 - val_acc: 0.7472\n",
      "Epoch 482/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0427 - acc: 0.9553 - val_loss: 0.2296 - val_acc: 0.7582\n",
      "Epoch 483/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0429 - acc: 0.9537 - val_loss: 0.2215 - val_acc: 0.7606\n",
      "Epoch 484/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0425 - acc: 0.9547 - val_loss: 0.2270 - val_acc: 0.7524\n",
      "Epoch 485/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0425 - acc: 0.9547 - val_loss: 0.2246 - val_acc: 0.7592\n",
      "Epoch 486/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0429 - acc: 0.9548 - val_loss: 0.2348 - val_acc: 0.7452\n",
      "Epoch 487/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0423 - acc: 0.9548 - val_loss: 0.2300 - val_acc: 0.7587\n",
      "Epoch 488/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0424 - acc: 0.9548 - val_loss: 0.2339 - val_acc: 0.7607\n",
      "Epoch 489/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0418 - acc: 0.9549 - val_loss: 0.2337 - val_acc: 0.7484\n",
      "Epoch 490/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0428 - acc: 0.9546 - val_loss: 0.2244 - val_acc: 0.7549\n",
      "Epoch 491/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0419 - acc: 0.9554 - val_loss: 0.2389 - val_acc: 0.7497\n",
      "Epoch 492/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0423 - acc: 0.9543 - val_loss: 0.2402 - val_acc: 0.7510\n",
      "Epoch 493/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0423 - acc: 0.9549 - val_loss: 0.2297 - val_acc: 0.7570\n",
      "Epoch 494/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0415 - acc: 0.9557 - val_loss: 0.2238 - val_acc: 0.7591\n",
      "Epoch 495/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0415 - acc: 0.9564 - val_loss: 0.2267 - val_acc: 0.7544\n",
      "Epoch 496/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0418 - acc: 0.9552 - val_loss: 0.2294 - val_acc: 0.7577\n",
      "Epoch 497/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0415 - acc: 0.9556 - val_loss: 0.2377 - val_acc: 0.7469\n",
      "Epoch 498/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0417 - acc: 0.9559 - val_loss: 0.2340 - val_acc: 0.7519\n",
      "Epoch 499/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0419 - acc: 0.9555 - val_loss: 0.2314 - val_acc: 0.7484\n",
      "Epoch 500/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0415 - acc: 0.9560 - val_loss: 0.2322 - val_acc: 0.7537\n",
      "Epoch 501/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0420 - acc: 0.9556 - val_loss: 0.2358 - val_acc: 0.7539\n",
      "Epoch 502/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0412 - acc: 0.9558 - val_loss: 0.2255 - val_acc: 0.7602\n",
      "Epoch 503/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0415 - acc: 0.9557 - val_loss: 0.2339 - val_acc: 0.7534\n",
      "Epoch 504/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0412 - acc: 0.9570 - val_loss: 0.2361 - val_acc: 0.7540\n",
      "Epoch 505/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0416 - acc: 0.9557 - val_loss: 0.2212 - val_acc: 0.7601\n",
      "Epoch 506/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0415 - acc: 0.9557 - val_loss: 0.2384 - val_acc: 0.7455\n",
      "Epoch 507/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0410 - acc: 0.9562 - val_loss: 0.2236 - val_acc: 0.7552\n",
      "Epoch 508/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0409 - acc: 0.9572 - val_loss: 0.2337 - val_acc: 0.7495\n",
      "Epoch 509/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0414 - acc: 0.9555 - val_loss: 0.2275 - val_acc: 0.7582\n",
      "Epoch 510/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0412 - acc: 0.9564 - val_loss: 0.2278 - val_acc: 0.7565\n",
      "Epoch 511/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0407 - acc: 0.9571 - val_loss: 0.2464 - val_acc: 0.7499\n",
      "Epoch 512/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0408 - acc: 0.9565 - val_loss: 0.2336 - val_acc: 0.7512\n",
      "Epoch 513/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0410 - acc: 0.9560 - val_loss: 0.2323 - val_acc: 0.7495\n",
      "Epoch 514/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0408 - acc: 0.9567 - val_loss: 0.2455 - val_acc: 0.7437\n",
      "Epoch 515/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0408 - acc: 0.9574 - val_loss: 0.2427 - val_acc: 0.7507\n",
      "Epoch 516/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0409 - acc: 0.9564 - val_loss: 0.2454 - val_acc: 0.7430\n",
      "Epoch 517/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0407 - acc: 0.9575 - val_loss: 0.2319 - val_acc: 0.7487\n",
      "Epoch 518/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0407 - acc: 0.9568 - val_loss: 0.2256 - val_acc: 0.7569\n",
      "Epoch 519/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0406 - acc: 0.9569 - val_loss: 0.2264 - val_acc: 0.7601\n",
      "Epoch 520/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0405 - acc: 0.9572 - val_loss: 0.2370 - val_acc: 0.7474\n",
      "Epoch 521/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0401 - acc: 0.9582 - val_loss: 0.2287 - val_acc: 0.7559\n",
      "Epoch 522/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0402 - acc: 0.9574 - val_loss: 0.2292 - val_acc: 0.7587\n",
      "Epoch 523/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0401 - acc: 0.9578 - val_loss: 0.2279 - val_acc: 0.7584\n",
      "Epoch 524/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0402 - acc: 0.9574 - val_loss: 0.2339 - val_acc: 0.7477\n",
      "Epoch 525/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0401 - acc: 0.9577 - val_loss: 0.2301 - val_acc: 0.7577\n",
      "Epoch 526/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0400 - acc: 0.9576 - val_loss: 0.2483 - val_acc: 0.7410\n",
      "Epoch 527/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0406 - acc: 0.9564 - val_loss: 0.2328 - val_acc: 0.7509\n",
      "Epoch 528/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0400 - acc: 0.9582 - val_loss: 0.2386 - val_acc: 0.7524\n",
      "Epoch 529/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0404 - acc: 0.9569 - val_loss: 0.2494 - val_acc: 0.7397\n",
      "Epoch 530/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0396 - acc: 0.9592 - val_loss: 0.2376 - val_acc: 0.7524\n",
      "Epoch 531/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0398 - acc: 0.9581 - val_loss: 0.2316 - val_acc: 0.7530\n",
      "Epoch 532/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0398 - acc: 0.9583 - val_loss: 0.2429 - val_acc: 0.7464\n",
      "Epoch 533/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0402 - acc: 0.9572 - val_loss: 0.2513 - val_acc: 0.7429\n",
      "Epoch 534/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0401 - acc: 0.9577 - val_loss: 0.2372 - val_acc: 0.7494\n",
      "Epoch 535/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0401 - acc: 0.9571 - val_loss: 0.2360 - val_acc: 0.7482\n",
      "Epoch 536/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0398 - acc: 0.9581 - val_loss: 0.2306 - val_acc: 0.7601\n",
      "Epoch 537/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0400 - acc: 0.9583 - val_loss: 0.2340 - val_acc: 0.7557\n",
      "Epoch 538/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0396 - acc: 0.9580 - val_loss: 0.2384 - val_acc: 0.7469\n",
      "Epoch 539/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0397 - acc: 0.9588 - val_loss: 0.2408 - val_acc: 0.7510\n",
      "Epoch 540/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0396 - acc: 0.9580 - val_loss: 0.2387 - val_acc: 0.7497\n",
      "Epoch 541/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0396 - acc: 0.9581 - val_loss: 0.2311 - val_acc: 0.7562\n",
      "Epoch 542/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0393 - acc: 0.9582 - val_loss: 0.2310 - val_acc: 0.7522\n",
      "Epoch 543/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0389 - acc: 0.9590 - val_loss: 0.2329 - val_acc: 0.7537\n",
      "Epoch 544/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0396 - acc: 0.9587 - val_loss: 0.2290 - val_acc: 0.7557\n",
      "Epoch 545/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0393 - acc: 0.9594 - val_loss: 0.2332 - val_acc: 0.7565\n",
      "Epoch 546/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0389 - acc: 0.9590 - val_loss: 0.2371 - val_acc: 0.7539\n",
      "Epoch 547/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0389 - acc: 0.9602 - val_loss: 0.2334 - val_acc: 0.7507\n",
      "Epoch 548/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0390 - acc: 0.9591 - val_loss: 0.2314 - val_acc: 0.7539\n",
      "Epoch 549/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0387 - acc: 0.9599 - val_loss: 0.2388 - val_acc: 0.7440\n",
      "Epoch 550/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0394 - acc: 0.9596 - val_loss: 0.2363 - val_acc: 0.7487\n",
      "Epoch 551/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0390 - acc: 0.9595 - val_loss: 0.2439 - val_acc: 0.7447\n",
      "Epoch 552/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0390 - acc: 0.9594 - val_loss: 0.2383 - val_acc: 0.7505\n",
      "Epoch 553/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0391 - acc: 0.9589 - val_loss: 0.2322 - val_acc: 0.7562\n",
      "Epoch 554/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0385 - acc: 0.9597 - val_loss: 0.2453 - val_acc: 0.7459\n",
      "Epoch 555/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0388 - acc: 0.9600 - val_loss: 0.2352 - val_acc: 0.7489\n",
      "Epoch 556/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0391 - acc: 0.9587 - val_loss: 0.2377 - val_acc: 0.7534\n",
      "Epoch 557/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0383 - acc: 0.9612 - val_loss: 0.2414 - val_acc: 0.7469\n",
      "Epoch 558/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0391 - acc: 0.9590 - val_loss: 0.2227 - val_acc: 0.7597\n",
      "Epoch 559/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0387 - acc: 0.9597 - val_loss: 0.2306 - val_acc: 0.7535\n",
      "Epoch 560/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0385 - acc: 0.9602 - val_loss: 0.2308 - val_acc: 0.7560\n",
      "Epoch 561/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0385 - acc: 0.9602 - val_loss: 0.2349 - val_acc: 0.7545\n",
      "Epoch 562/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0383 - acc: 0.9597 - val_loss: 0.2478 - val_acc: 0.7422\n",
      "Epoch 563/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0382 - acc: 0.9607 - val_loss: 0.2426 - val_acc: 0.7480\n",
      "Epoch 564/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0382 - acc: 0.9600 - val_loss: 0.2387 - val_acc: 0.7475\n",
      "Epoch 565/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0383 - acc: 0.9597 - val_loss: 0.2260 - val_acc: 0.7584\n",
      "Epoch 566/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0382 - acc: 0.9599 - val_loss: 0.2305 - val_acc: 0.7552\n",
      "Epoch 567/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0382 - acc: 0.9596 - val_loss: 0.2317 - val_acc: 0.7519\n",
      "Epoch 568/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0382 - acc: 0.9606 - val_loss: 0.2368 - val_acc: 0.7569\n",
      "Epoch 569/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0381 - acc: 0.9595 - val_loss: 0.2335 - val_acc: 0.7517\n",
      "Epoch 570/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0382 - acc: 0.9600 - val_loss: 0.2431 - val_acc: 0.7549\n",
      "Epoch 571/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0384 - acc: 0.9599 - val_loss: 0.2231 - val_acc: 0.7622\n",
      "Epoch 572/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0379 - acc: 0.9604 - val_loss: 0.2316 - val_acc: 0.7559\n",
      "Epoch 573/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0374 - acc: 0.9611 - val_loss: 0.2379 - val_acc: 0.7520\n",
      "Epoch 574/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0380 - acc: 0.9603 - val_loss: 0.2310 - val_acc: 0.7539\n",
      "Epoch 575/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0378 - acc: 0.9606 - val_loss: 0.2291 - val_acc: 0.7592\n",
      "Epoch 576/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0380 - acc: 0.9601 - val_loss: 0.2298 - val_acc: 0.7577\n",
      "Epoch 577/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0377 - acc: 0.9602 - val_loss: 0.2270 - val_acc: 0.7572\n",
      "Epoch 578/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0375 - acc: 0.9611 - val_loss: 0.2345 - val_acc: 0.7559\n",
      "Epoch 579/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0378 - acc: 0.9601 - val_loss: 0.2431 - val_acc: 0.7504\n",
      "Epoch 580/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0373 - acc: 0.9614 - val_loss: 0.2349 - val_acc: 0.7530\n",
      "Epoch 581/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0376 - acc: 0.9613 - val_loss: 0.2358 - val_acc: 0.7502\n",
      "Epoch 582/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0378 - acc: 0.9602 - val_loss: 0.2323 - val_acc: 0.7537\n",
      "Epoch 583/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0376 - acc: 0.9611 - val_loss: 0.2266 - val_acc: 0.7599\n",
      "Epoch 584/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0369 - acc: 0.9617 - val_loss: 0.2342 - val_acc: 0.7502\n",
      "Epoch 585/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0377 - acc: 0.9604 - val_loss: 0.2395 - val_acc: 0.7544\n",
      "Epoch 586/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0381 - acc: 0.9600 - val_loss: 0.2356 - val_acc: 0.7517\n",
      "Epoch 587/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0375 - acc: 0.9606 - val_loss: 0.2400 - val_acc: 0.7524\n",
      "Epoch 588/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0370 - acc: 0.9615 - val_loss: 0.2322 - val_acc: 0.7587\n",
      "Epoch 589/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0372 - acc: 0.9617 - val_loss: 0.2318 - val_acc: 0.7554\n",
      "Epoch 590/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0371 - acc: 0.9615 - val_loss: 0.2334 - val_acc: 0.7557\n",
      "Epoch 591/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0371 - acc: 0.9617 - val_loss: 0.2316 - val_acc: 0.7552\n",
      "Epoch 592/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0366 - acc: 0.9617 - val_loss: 0.2453 - val_acc: 0.7470\n",
      "Epoch 593/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0366 - acc: 0.9624 - val_loss: 0.2316 - val_acc: 0.7537\n",
      "Epoch 594/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0372 - acc: 0.9610 - val_loss: 0.2309 - val_acc: 0.7560\n",
      "Epoch 595/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0370 - acc: 0.9616 - val_loss: 0.2392 - val_acc: 0.7467\n",
      "Epoch 596/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0368 - acc: 0.9617 - val_loss: 0.2255 - val_acc: 0.7591\n",
      "Epoch 597/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0367 - acc: 0.9624 - val_loss: 0.2251 - val_acc: 0.7611\n",
      "Epoch 598/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0363 - acc: 0.9622 - val_loss: 0.2386 - val_acc: 0.7544\n",
      "Epoch 599/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0366 - acc: 0.9612 - val_loss: 0.2338 - val_acc: 0.7547\n",
      "Epoch 600/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0369 - acc: 0.9612 - val_loss: 0.2400 - val_acc: 0.7482\n",
      "Epoch 601/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0367 - acc: 0.9624 - val_loss: 0.2340 - val_acc: 0.7545\n",
      "Epoch 602/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0364 - acc: 0.9621 - val_loss: 0.2281 - val_acc: 0.7532\n",
      "Epoch 603/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0366 - acc: 0.9623 - val_loss: 0.2271 - val_acc: 0.7597\n",
      "Epoch 604/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0362 - acc: 0.9620 - val_loss: 0.2327 - val_acc: 0.7557\n",
      "Epoch 605/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0363 - acc: 0.9618 - val_loss: 0.2386 - val_acc: 0.7529\n",
      "Epoch 606/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0366 - acc: 0.9620 - val_loss: 0.2327 - val_acc: 0.7535\n",
      "Epoch 607/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0357 - acc: 0.9630 - val_loss: 0.2392 - val_acc: 0.7507\n",
      "Epoch 608/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0367 - acc: 0.9622 - val_loss: 0.2432 - val_acc: 0.7474\n",
      "Epoch 609/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0366 - acc: 0.9622 - val_loss: 0.2410 - val_acc: 0.7485\n",
      "Epoch 610/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0362 - acc: 0.9635 - val_loss: 0.2437 - val_acc: 0.7522\n",
      "Epoch 611/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0364 - acc: 0.9619 - val_loss: 0.2366 - val_acc: 0.7535\n",
      "Epoch 612/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0361 - acc: 0.9621 - val_loss: 0.2431 - val_acc: 0.7502\n",
      "Epoch 613/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0361 - acc: 0.9631 - val_loss: 0.2348 - val_acc: 0.7514\n",
      "Epoch 614/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0363 - acc: 0.9627 - val_loss: 0.2291 - val_acc: 0.7577\n",
      "Epoch 615/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0360 - acc: 0.9630 - val_loss: 0.2453 - val_acc: 0.7490\n",
      "Epoch 616/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0357 - acc: 0.9620 - val_loss: 0.2417 - val_acc: 0.7469\n",
      "Epoch 617/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0359 - acc: 0.9640 - val_loss: 0.2396 - val_acc: 0.7517\n",
      "Epoch 618/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0362 - acc: 0.9620 - val_loss: 0.2332 - val_acc: 0.7534\n",
      "Epoch 619/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0359 - acc: 0.9632 - val_loss: 0.2382 - val_acc: 0.7494\n",
      "Epoch 620/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0358 - acc: 0.9633 - val_loss: 0.2410 - val_acc: 0.7475\n",
      "Epoch 621/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0356 - acc: 0.9631 - val_loss: 0.2365 - val_acc: 0.7484\n",
      "Epoch 622/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0353 - acc: 0.9635 - val_loss: 0.2295 - val_acc: 0.7562\n",
      "Epoch 623/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0355 - acc: 0.9629 - val_loss: 0.2339 - val_acc: 0.7539\n",
      "Epoch 624/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0352 - acc: 0.9644 - val_loss: 0.2358 - val_acc: 0.7540\n",
      "Epoch 625/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0353 - acc: 0.9629 - val_loss: 0.2414 - val_acc: 0.7500\n",
      "Epoch 626/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0356 - acc: 0.9631 - val_loss: 0.2376 - val_acc: 0.7547\n",
      "Epoch 627/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0357 - acc: 0.9630 - val_loss: 0.2438 - val_acc: 0.7482\n",
      "Epoch 628/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0354 - acc: 0.9635 - val_loss: 0.2480 - val_acc: 0.7407\n",
      "Epoch 629/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0352 - acc: 0.9638 - val_loss: 0.2445 - val_acc: 0.7502\n",
      "Epoch 630/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0352 - acc: 0.9637 - val_loss: 0.2406 - val_acc: 0.7530\n",
      "Epoch 631/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0359 - acc: 0.9634 - val_loss: 0.2418 - val_acc: 0.7510\n",
      "Epoch 632/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0355 - acc: 0.9624 - val_loss: 0.2394 - val_acc: 0.7520\n",
      "Epoch 633/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0349 - acc: 0.9652 - val_loss: 0.2323 - val_acc: 0.7554\n",
      "Epoch 634/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0346 - acc: 0.9644 - val_loss: 0.2370 - val_acc: 0.7515\n",
      "Epoch 635/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0351 - acc: 0.9641 - val_loss: 0.2323 - val_acc: 0.7584\n",
      "Epoch 636/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0357 - acc: 0.9631 - val_loss: 0.2340 - val_acc: 0.7520\n",
      "Epoch 637/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0353 - acc: 0.9630 - val_loss: 0.2408 - val_acc: 0.7509\n",
      "Epoch 638/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0349 - acc: 0.9634 - val_loss: 0.2352 - val_acc: 0.7540\n",
      "Epoch 639/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0357 - acc: 0.9632 - val_loss: 0.2360 - val_acc: 0.7567\n",
      "Epoch 640/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0354 - acc: 0.9635 - val_loss: 0.2355 - val_acc: 0.7515\n",
      "Epoch 641/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0352 - acc: 0.9630 - val_loss: 0.2400 - val_acc: 0.7480\n",
      "Epoch 642/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0354 - acc: 0.9648 - val_loss: 0.2415 - val_acc: 0.7492\n",
      "Epoch 643/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0350 - acc: 0.9643 - val_loss: 0.2411 - val_acc: 0.7497\n",
      "Epoch 644/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0346 - acc: 0.9642 - val_loss: 0.2336 - val_acc: 0.7539\n",
      "Epoch 645/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0349 - acc: 0.9640 - val_loss: 0.2530 - val_acc: 0.7432\n",
      "Epoch 646/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0348 - acc: 0.9637 - val_loss: 0.2391 - val_acc: 0.7514\n",
      "Epoch 647/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0351 - acc: 0.9642 - val_loss: 0.2402 - val_acc: 0.7484\n",
      "Epoch 648/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0349 - acc: 0.9642 - val_loss: 0.2425 - val_acc: 0.7479\n",
      "Epoch 649/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0352 - acc: 0.9637 - val_loss: 0.2353 - val_acc: 0.7492\n",
      "Epoch 650/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0345 - acc: 0.9650 - val_loss: 0.2425 - val_acc: 0.7490\n",
      "Epoch 651/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0346 - acc: 0.9644 - val_loss: 0.2256 - val_acc: 0.7609\n",
      "Epoch 652/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0349 - acc: 0.9641 - val_loss: 0.2342 - val_acc: 0.7560\n",
      "Epoch 653/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0344 - acc: 0.9655 - val_loss: 0.2344 - val_acc: 0.7527\n",
      "Epoch 654/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0341 - acc: 0.9656 - val_loss: 0.2399 - val_acc: 0.7532\n",
      "Epoch 655/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0344 - acc: 0.9645 - val_loss: 0.2335 - val_acc: 0.7499\n",
      "Epoch 656/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0348 - acc: 0.9640 - val_loss: 0.2412 - val_acc: 0.7442\n",
      "Epoch 657/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0343 - acc: 0.9653 - val_loss: 0.2346 - val_acc: 0.7567\n",
      "Epoch 658/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0345 - acc: 0.9645 - val_loss: 0.2378 - val_acc: 0.7544\n",
      "Epoch 659/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0344 - acc: 0.9646 - val_loss: 0.2309 - val_acc: 0.7524\n",
      "Epoch 660/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0343 - acc: 0.9641 - val_loss: 0.2376 - val_acc: 0.7519\n",
      "Epoch 661/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0342 - acc: 0.9648 - val_loss: 0.2422 - val_acc: 0.7504\n",
      "Epoch 662/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0340 - acc: 0.9652 - val_loss: 0.2463 - val_acc: 0.7467\n",
      "Epoch 663/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0341 - acc: 0.9648 - val_loss: 0.2343 - val_acc: 0.7540\n",
      "Epoch 664/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0341 - acc: 0.9655 - val_loss: 0.2388 - val_acc: 0.7519\n",
      "Epoch 665/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0341 - acc: 0.9654 - val_loss: 0.2320 - val_acc: 0.7520\n",
      "Epoch 666/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0338 - acc: 0.9655 - val_loss: 0.2414 - val_acc: 0.7464\n",
      "Epoch 667/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0345 - acc: 0.9645 - val_loss: 0.2450 - val_acc: 0.7465\n",
      "Epoch 668/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0340 - acc: 0.9655 - val_loss: 0.2423 - val_acc: 0.7507\n",
      "Epoch 669/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0338 - acc: 0.9656 - val_loss: 0.2371 - val_acc: 0.7550\n",
      "Epoch 670/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0343 - acc: 0.9664 - val_loss: 0.2333 - val_acc: 0.7564\n",
      "Epoch 671/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0339 - acc: 0.9655 - val_loss: 0.2402 - val_acc: 0.7482\n",
      "Epoch 672/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0334 - acc: 0.9658 - val_loss: 0.2310 - val_acc: 0.7537\n",
      "Epoch 673/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0337 - acc: 0.9653 - val_loss: 0.2411 - val_acc: 0.7497\n",
      "Epoch 674/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0338 - acc: 0.9658 - val_loss: 0.2354 - val_acc: 0.7532\n",
      "Epoch 675/800\n",
      "23972/23972 [==============================] - 2s 69us/step - loss: 0.0338 - acc: 0.9645 - val_loss: 0.2438 - val_acc: 0.7460\n",
      "Epoch 676/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0340 - acc: 0.9650 - val_loss: 0.2397 - val_acc: 0.7459\n",
      "Epoch 677/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0337 - acc: 0.9651 - val_loss: 0.2429 - val_acc: 0.7464\n",
      "Epoch 678/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0337 - acc: 0.9648 - val_loss: 0.2349 - val_acc: 0.7510\n",
      "Epoch 679/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0336 - acc: 0.9660 - val_loss: 0.2455 - val_acc: 0.7455\n",
      "Epoch 680/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0336 - acc: 0.9656 - val_loss: 0.2414 - val_acc: 0.7492\n",
      "Epoch 681/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0334 - acc: 0.9654 - val_loss: 0.2459 - val_acc: 0.7467\n",
      "Epoch 682/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0334 - acc: 0.9657 - val_loss: 0.2338 - val_acc: 0.7535\n",
      "Epoch 683/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0331 - acc: 0.9668 - val_loss: 0.2362 - val_acc: 0.7502\n",
      "Epoch 684/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0339 - acc: 0.9655 - val_loss: 0.2405 - val_acc: 0.7475\n",
      "Epoch 685/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0334 - acc: 0.9662 - val_loss: 0.2370 - val_acc: 0.7522\n",
      "Epoch 686/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0332 - acc: 0.9663 - val_loss: 0.2277 - val_acc: 0.7601\n",
      "Epoch 687/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0332 - acc: 0.9668 - val_loss: 0.2393 - val_acc: 0.7482\n",
      "Epoch 688/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0331 - acc: 0.9660 - val_loss: 0.2486 - val_acc: 0.7432\n",
      "Epoch 689/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0337 - acc: 0.9654 - val_loss: 0.2313 - val_acc: 0.7545\n",
      "Epoch 690/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0330 - acc: 0.9662 - val_loss: 0.2357 - val_acc: 0.7559\n",
      "Epoch 691/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0334 - acc: 0.9658 - val_loss: 0.2397 - val_acc: 0.7515\n",
      "Epoch 692/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0332 - acc: 0.9659 - val_loss: 0.2481 - val_acc: 0.7420\n",
      "Epoch 693/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0334 - acc: 0.9655 - val_loss: 0.2413 - val_acc: 0.7502\n",
      "Epoch 694/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0329 - acc: 0.9668 - val_loss: 0.2295 - val_acc: 0.7555\n",
      "Epoch 695/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0330 - acc: 0.9666 - val_loss: 0.2293 - val_acc: 0.7576\n",
      "Epoch 696/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0329 - acc: 0.9668 - val_loss: 0.2342 - val_acc: 0.7560\n",
      "Epoch 697/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0329 - acc: 0.9674 - val_loss: 0.2502 - val_acc: 0.7450\n",
      "Epoch 698/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0331 - acc: 0.9673 - val_loss: 0.2377 - val_acc: 0.7524\n",
      "Epoch 699/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.0330 - acc: 0.9666 - val_loss: 0.2505 - val_acc: 0.7399\n",
      "Epoch 700/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0329 - acc: 0.9668 - val_loss: 0.2433 - val_acc: 0.7527\n",
      "Epoch 701/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0328 - acc: 0.9666 - val_loss: 0.2422 - val_acc: 0.7510\n",
      "Epoch 702/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0326 - acc: 0.9657 - val_loss: 0.2386 - val_acc: 0.7469\n",
      "Epoch 703/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0330 - acc: 0.9672 - val_loss: 0.2367 - val_acc: 0.7510\n",
      "Epoch 704/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0332 - acc: 0.9661 - val_loss: 0.2363 - val_acc: 0.7517\n",
      "Epoch 705/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0327 - acc: 0.9668 - val_loss: 0.2435 - val_acc: 0.7464\n",
      "Epoch 706/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0329 - acc: 0.9667 - val_loss: 0.2485 - val_acc: 0.7452\n",
      "Epoch 707/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0326 - acc: 0.9673 - val_loss: 0.2453 - val_acc: 0.7430\n",
      "Epoch 708/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0327 - acc: 0.9666 - val_loss: 0.2366 - val_acc: 0.7547\n",
      "Epoch 709/800\n",
      "23972/23972 [==============================] - 1s 44us/step - loss: 0.0328 - acc: 0.9665 - val_loss: 0.2425 - val_acc: 0.7502\n",
      "Epoch 710/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0322 - acc: 0.9677 - val_loss: 0.2470 - val_acc: 0.7449\n",
      "Epoch 711/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0329 - acc: 0.9661 - val_loss: 0.2310 - val_acc: 0.7596\n",
      "Epoch 712/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0322 - acc: 0.9673 - val_loss: 0.2334 - val_acc: 0.7596\n",
      "Epoch 713/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0327 - acc: 0.9672 - val_loss: 0.2462 - val_acc: 0.7484\n",
      "Epoch 714/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0325 - acc: 0.9668 - val_loss: 0.2410 - val_acc: 0.7472\n",
      "Epoch 715/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0328 - acc: 0.9668 - val_loss: 0.2404 - val_acc: 0.7522\n",
      "Epoch 716/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0322 - acc: 0.9667 - val_loss: 0.2476 - val_acc: 0.7422\n",
      "Epoch 717/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0324 - acc: 0.9669 - val_loss: 0.2375 - val_acc: 0.7544\n",
      "Epoch 718/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0328 - acc: 0.9665 - val_loss: 0.2322 - val_acc: 0.7545\n",
      "Epoch 719/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0320 - acc: 0.9674 - val_loss: 0.2389 - val_acc: 0.7529\n",
      "Epoch 720/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0325 - acc: 0.9666 - val_loss: 0.2417 - val_acc: 0.7480\n",
      "Epoch 721/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0329 - acc: 0.9669 - val_loss: 0.2458 - val_acc: 0.7464\n",
      "Epoch 722/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0322 - acc: 0.9676 - val_loss: 0.2362 - val_acc: 0.7534\n",
      "Epoch 723/800\n",
      "23972/23972 [==============================] - 1s 46us/step - loss: 0.0318 - acc: 0.9683 - val_loss: 0.2349 - val_acc: 0.7557\n",
      "Epoch 724/800\n",
      "23972/23972 [==============================] - 1s 45us/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.2410 - val_acc: 0.7502\n",
      "Epoch 725/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0320 - acc: 0.9672 - val_loss: 0.2427 - val_acc: 0.7487\n",
      "Epoch 726/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0321 - acc: 0.9677 - val_loss: 0.2494 - val_acc: 0.7432\n",
      "Epoch 727/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0322 - acc: 0.9668 - val_loss: 0.2371 - val_acc: 0.7532\n",
      "Epoch 728/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0322 - acc: 0.9680 - val_loss: 0.2412 - val_acc: 0.7484\n",
      "Epoch 729/800\n",
      "23972/23972 [==============================] - 1s 49us/step - loss: 0.0324 - acc: 0.9659 - val_loss: 0.2397 - val_acc: 0.7520\n",
      "Epoch 730/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0321 - acc: 0.9676 - val_loss: 0.2394 - val_acc: 0.7510\n",
      "Epoch 731/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0318 - acc: 0.9683 - val_loss: 0.2426 - val_acc: 0.7500\n",
      "Epoch 732/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0319 - acc: 0.9675 - val_loss: 0.2329 - val_acc: 0.7559\n",
      "Epoch 733/800\n",
      "23972/23972 [==============================] - 1s 62us/step - loss: 0.0317 - acc: 0.9671 - val_loss: 0.2365 - val_acc: 0.7535\n",
      "Epoch 734/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0319 - acc: 0.9673 - val_loss: 0.2356 - val_acc: 0.7510\n",
      "Epoch 735/800\n",
      "23972/23972 [==============================] - 2s 67us/step - loss: 0.0316 - acc: 0.9687 - val_loss: 0.2419 - val_acc: 0.7450\n",
      "Epoch 736/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0315 - acc: 0.9688 - val_loss: 0.2437 - val_acc: 0.7479\n",
      "Epoch 737/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0318 - acc: 0.9668 - val_loss: 0.2384 - val_acc: 0.7535\n",
      "Epoch 738/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0317 - acc: 0.9683 - val_loss: 0.2408 - val_acc: 0.7487\n",
      "Epoch 739/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0317 - acc: 0.9682 - val_loss: 0.2408 - val_acc: 0.7505\n",
      "Epoch 740/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0318 - acc: 0.9681 - val_loss: 0.2435 - val_acc: 0.7479\n",
      "Epoch 741/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0322 - acc: 0.9676 - val_loss: 0.2495 - val_acc: 0.7419\n",
      "Epoch 742/800\n",
      "23972/23972 [==============================] - 2s 75us/step - loss: 0.0316 - acc: 0.9685 - val_loss: 0.2361 - val_acc: 0.7519\n",
      "Epoch 743/800\n",
      "23972/23972 [==============================] - 2s 74us/step - loss: 0.0319 - acc: 0.9683 - val_loss: 0.2505 - val_acc: 0.7437\n",
      "Epoch 744/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0319 - acc: 0.9674 - val_loss: 0.2411 - val_acc: 0.7497\n",
      "Epoch 745/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0318 - acc: 0.9675 - val_loss: 0.2417 - val_acc: 0.7510\n",
      "Epoch 746/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0314 - acc: 0.9683 - val_loss: 0.2449 - val_acc: 0.7499\n",
      "Epoch 747/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0316 - acc: 0.9683 - val_loss: 0.2289 - val_acc: 0.7569\n",
      "Epoch 748/800\n",
      "23972/23972 [==============================] - 2s 69us/step - loss: 0.0319 - acc: 0.9674 - val_loss: 0.2550 - val_acc: 0.7364\n",
      "Epoch 749/800\n",
      "23972/23972 [==============================] - 2s 72us/step - loss: 0.0310 - acc: 0.9682 - val_loss: 0.2394 - val_acc: 0.7474\n",
      "Epoch 750/800\n",
      "23972/23972 [==============================] - 2s 70us/step - loss: 0.0318 - acc: 0.9680 - val_loss: 0.2451 - val_acc: 0.7480\n",
      "Epoch 751/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0312 - acc: 0.9690 - val_loss: 0.2381 - val_acc: 0.7457\n",
      "Epoch 752/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0315 - acc: 0.9682 - val_loss: 0.2466 - val_acc: 0.7440\n",
      "Epoch 753/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0312 - acc: 0.9688 - val_loss: 0.2436 - val_acc: 0.7492\n",
      "Epoch 754/800\n",
      "23972/23972 [==============================] - 2s 63us/step - loss: 0.0323 - acc: 0.9675 - val_loss: 0.2407 - val_acc: 0.7504\n",
      "Epoch 755/800\n",
      "23972/23972 [==============================] - 2s 71us/step - loss: 0.0314 - acc: 0.9680 - val_loss: 0.2386 - val_acc: 0.7489\n",
      "Epoch 756/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0316 - acc: 0.9677 - val_loss: 0.2357 - val_acc: 0.7549\n",
      "Epoch 757/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0308 - acc: 0.9692 - val_loss: 0.2474 - val_acc: 0.7455\n",
      "Epoch 758/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0317 - acc: 0.9679 - val_loss: 0.2343 - val_acc: 0.7524\n",
      "Epoch 759/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0313 - acc: 0.9694 - val_loss: 0.2307 - val_acc: 0.7591\n",
      "Epoch 760/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0314 - acc: 0.9684 - val_loss: 0.2405 - val_acc: 0.7489\n",
      "Epoch 761/800\n",
      "23972/23972 [==============================] - 1s 58us/step - loss: 0.0316 - acc: 0.9685 - val_loss: 0.2380 - val_acc: 0.7485\n",
      "Epoch 762/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0313 - acc: 0.9685 - val_loss: 0.2447 - val_acc: 0.7519\n",
      "Epoch 763/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0312 - acc: 0.9685 - val_loss: 0.2464 - val_acc: 0.7467\n",
      "Epoch 764/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0314 - acc: 0.9681 - val_loss: 0.2428 - val_acc: 0.7459\n",
      "Epoch 765/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0313 - acc: 0.9690 - val_loss: 0.2399 - val_acc: 0.7524\n",
      "Epoch 766/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0310 - acc: 0.9691 - val_loss: 0.2350 - val_acc: 0.7559\n",
      "Epoch 767/800\n",
      "23972/23972 [==============================] - 1s 59us/step - loss: 0.0313 - acc: 0.9684 - val_loss: 0.2399 - val_acc: 0.7509\n",
      "Epoch 768/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0314 - acc: 0.9684 - val_loss: 0.2378 - val_acc: 0.7494\n",
      "Epoch 769/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0313 - acc: 0.9675 - val_loss: 0.2468 - val_acc: 0.7419\n",
      "Epoch 770/800\n",
      "23972/23972 [==============================] - 1s 55us/step - loss: 0.0314 - acc: 0.9689 - val_loss: 0.2419 - val_acc: 0.7499\n",
      "Epoch 771/800\n",
      "23972/23972 [==============================] - 1s 54us/step - loss: 0.0311 - acc: 0.9688 - val_loss: 0.2429 - val_acc: 0.7467\n",
      "Epoch 772/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0311 - acc: 0.9687 - val_loss: 0.2375 - val_acc: 0.7455\n",
      "Epoch 773/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0309 - acc: 0.9684 - val_loss: 0.2450 - val_acc: 0.7477\n",
      "Epoch 774/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0304 - acc: 0.9701 - val_loss: 0.2392 - val_acc: 0.7495\n",
      "Epoch 775/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0309 - acc: 0.9693 - val_loss: 0.2494 - val_acc: 0.7432\n",
      "Epoch 776/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0309 - acc: 0.9691 - val_loss: 0.2488 - val_acc: 0.7449\n",
      "Epoch 777/800\n",
      "23972/23972 [==============================] - 1s 56us/step - loss: 0.0312 - acc: 0.9684 - val_loss: 0.2402 - val_acc: 0.7469\n",
      "Epoch 778/800\n",
      "23972/23972 [==============================] - 1s 53us/step - loss: 0.0308 - acc: 0.9693 - val_loss: 0.2418 - val_acc: 0.7510\n",
      "Epoch 779/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0305 - acc: 0.9702 - val_loss: 0.2452 - val_acc: 0.7469\n",
      "Epoch 780/800\n",
      "23972/23972 [==============================] - 1s 52us/step - loss: 0.0308 - acc: 0.9695 - val_loss: 0.2456 - val_acc: 0.7469\n",
      "Epoch 781/800\n",
      "23972/23972 [==============================] - 1s 51us/step - loss: 0.0299 - acc: 0.9707 - val_loss: 0.2372 - val_acc: 0.7520\n",
      "Epoch 782/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0308 - acc: 0.9694 - val_loss: 0.2443 - val_acc: 0.7470\n",
      "Epoch 783/800\n",
      "23972/23972 [==============================] - 1s 47us/step - loss: 0.0308 - acc: 0.9697 - val_loss: 0.2385 - val_acc: 0.7537\n",
      "Epoch 784/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0306 - acc: 0.9700 - val_loss: 0.2304 - val_acc: 0.7532\n",
      "Epoch 785/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0305 - acc: 0.9691 - val_loss: 0.2293 - val_acc: 0.7557\n",
      "Epoch 786/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0309 - acc: 0.9686 - val_loss: 0.2408 - val_acc: 0.7485\n",
      "Epoch 787/800\n",
      "23972/23972 [==============================] - 1s 50us/step - loss: 0.0303 - acc: 0.9700 - val_loss: 0.2403 - val_acc: 0.7549\n",
      "Epoch 788/800\n",
      "23972/23972 [==============================] - 1s 48us/step - loss: 0.0308 - acc: 0.9685 - val_loss: 0.2385 - val_acc: 0.7522\n",
      "Epoch 789/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0305 - acc: 0.9690 - val_loss: 0.2355 - val_acc: 0.7530\n",
      "Epoch 790/800\n",
      "23972/23972 [==============================] - 2s 68us/step - loss: 0.0305 - acc: 0.9700 - val_loss: 0.2427 - val_acc: 0.7490\n",
      "Epoch 791/800\n",
      "23972/23972 [==============================] - 2s 66us/step - loss: 0.0305 - acc: 0.9690 - val_loss: 0.2392 - val_acc: 0.7492\n",
      "Epoch 792/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0304 - acc: 0.9696 - val_loss: 0.2375 - val_acc: 0.7507\n",
      "Epoch 793/800\n",
      "23972/23972 [==============================] - 2s 64us/step - loss: 0.0303 - acc: 0.9705 - val_loss: 0.2339 - val_acc: 0.7524\n",
      "Epoch 794/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0307 - acc: 0.9696 - val_loss: 0.2372 - val_acc: 0.7515\n",
      "Epoch 795/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0306 - acc: 0.9690 - val_loss: 0.2389 - val_acc: 0.7540\n",
      "Epoch 796/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0303 - acc: 0.9694 - val_loss: 0.2352 - val_acc: 0.7507\n",
      "Epoch 797/800\n",
      "23972/23972 [==============================] - 1s 60us/step - loss: 0.0308 - acc: 0.9698 - val_loss: 0.2395 - val_acc: 0.7515\n",
      "Epoch 798/800\n",
      "23972/23972 [==============================] - 1s 57us/step - loss: 0.0305 - acc: 0.9693 - val_loss: 0.2304 - val_acc: 0.7534\n",
      "Epoch 799/800\n",
      "23972/23972 [==============================] - 2s 65us/step - loss: 0.0300 - acc: 0.9696 - val_loss: 0.2409 - val_acc: 0.7460\n",
      "Epoch 800/800\n",
      "23972/23972 [==============================] - 1s 61us/step - loss: 0.0306 - acc: 0.9698 - val_loss: 0.2498 - val_acc: 0.7442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x180911818d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=800,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulm\\Anaconda3\\envs\\pyten\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "1079 1320\n"
     ]
    }
   ],
   "source": [
    "p=model.predict_classes(X_test)\n",
    "print(y_test)\n",
    "y_test=list(y_test)\n",
    "#print(y_test[:100])\n",
    "p=p.ravel()\n",
    "p=list(p)\n",
    "print(p)\n",
    "#pp=p.sum()\n",
    "#yy=y_test.sum()\n",
    "#print(pp,yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749874853996329\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
